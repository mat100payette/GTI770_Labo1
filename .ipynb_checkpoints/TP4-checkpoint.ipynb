{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GTI770 - TP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import graphviz\n",
    "import decimal\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility methods\n",
    "def SplitVectorData_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitLabels_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = 1\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitVectorData_NoVal(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    test_portion = (1 - train_portion)\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_test\n",
    "\n",
    "def concatenateWithoutTestPortion(full_array, index):\n",
    "    result_array = []\n",
    "    for i in range(0, len(full_array)):\n",
    "        if len(result_array) == 0:\n",
    "            result_array = full_array[i]\n",
    "        elif i != index :\n",
    "            result_array = np.concatenate((result_array, full_array[i]), axis=0)\n",
    "    return result_array\n",
    "\n",
    "def scores_mean(array_scores):\n",
    "    \n",
    "    size = len(array_scores)\n",
    "    subsize = len(array_scores[0])\n",
    "    array_mean = np.zeros(subsize, dtype=float)\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        for j in range(0, subsize):\n",
    "            array_mean[j] += array_scores[i][j]\n",
    "            \n",
    "    for j in range(0, subsize):\n",
    "            array_mean[j] = array_mean[j] / size\n",
    "    \n",
    "    return array_mean\n",
    "\n",
    "def UseModelOnTestData(array, model, transformer=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if transformer is not None:\n",
    "        transform_train, transform_val, transform_test, Y_train, Y_val, Y_test = TransformData(array_train, array_val, array_test, len(array_train[0]), transformer)\n",
    "    array_model_result, array_prediction_train_result, array_prediction_val_result, array_prediction_test_result, array_train_result, array_val_result, array_test_result = GenerateModelDataFromTransform(transform_train, transform_val, transform_test, Y_train, Y_val, Y_test, len(array[0]), model)\n",
    "    result = [[array_test_result, array_prediction_test_result]]\n",
    "    return GenerateScores(result) \n",
    "\n",
    "# ----- For debug -----\n",
    "#Filter_train, Filter_val, Filter_test = SplitVectorDataTrainValTest(Filter, 0.6)\n",
    "#print(len(Filter_train))\n",
    "#print(len(Filter_val))\n",
    "#print(len(Filter_test))\n",
    "#print(len(Filter))\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Models generation methods\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return MinMaxScaler().fit_transform(data)\n",
    "\n",
    "def GenerateScoresFromModel(x, y, chosen_model):\n",
    "    \n",
    "    X_train, X_val, X_test = SplitVectorData_Holdout(x, 0.8)\n",
    "    Y_train, Y_val, Y_test = SplitLabels_Holdout(y, 0.8)\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, prediction_train], [Y_val, prediction_val], [Y_test, prediction_test]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def TransformData(array_train, array_val, array_test, num_features, chosen_transformer):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    data_train = array_train\n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "    \n",
    "    data_val = array_val\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "    \n",
    "    data_test = array_test\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    \n",
    "    transformer_train = chosen_transformer\n",
    "    transformer_train = transformer_train.fit_transform(X_train, Y_train)\n",
    "    \n",
    "    transformer_val = chosen_transformer\n",
    "    transformer_val = transformer_val.fit_transform(X_val, Y_val)\n",
    "    \n",
    "    transformer_test = chosen_transformer\n",
    "    transformer_test = transformer_test.fit_transform(X_test, Y_test)\n",
    "    return transformer_train, transformer_val, transformer_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def GenerateModelDataFromTransform(array_train, array_val, array_test, y_train, y_val, y_test, num_features, chosen_model):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    X_train  = array_train\n",
    "    Y_train = y_train\n",
    "    \n",
    "    X_val = array_val\n",
    "    Y_val = y_val\n",
    "    \n",
    "    X_test  = array_test\n",
    "    Y_test = y_test\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    return model, prediction_train, prediction_val, prediction_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def SplitLabelsFromPrimitives(data_train, data_val, data_test):\n",
    "    num_features = len(data_train[0]) - 1\n",
    "    \n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display methods\n",
    "def ExportTree(model):\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         #feature_names = ['', '', ''],  \n",
    "                         class_names = ['spam', 'mail'],\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render(\"Filter_data\") \n",
    "    return graph\n",
    "\n",
    "def GenerateScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "    F1Scores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "        F1Scores[i] = f1_score(array[i][0], array[i][1], average='weighted', labels=np.unique(array[i][1]))\n",
    "    \n",
    "    return AccScores, F1Scores\n",
    "\n",
    "def GenerateAccScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "    \n",
    "    return AccScores\n",
    "\n",
    "#Extraction de primitive\n",
    "def TracePlot(array_acc_X, array_acc_Y, array_f1_X, array_f1_Y, titre, titre_x, titre_y):        \n",
    "    \n",
    "    plt.plot(array_acc_X, array_acc_Y, 'ro')\n",
    "    plt.plot(array_f1_X, array_f1_Y, 'g*')\n",
    "    plt.xlabel(titre_x)\n",
    "    plt.ylabel(titre_y)\n",
    "    plt.legend(['Accuracy Score','F1 Score'])\n",
    "    plt.title(titre)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creations methods\n",
    "def DecisionTree_model(depth):\n",
    "    return tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth, min_samples_leaf=1)\n",
    "\n",
    "def CreateKNNModel(k, weight):\n",
    "    return KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "\n",
    "def RandomForest_model(nb_estim, depth, min_sample):\n",
    "    return RandomForestClassifier(n_estimators=nb_estim, max_depth=depth, min_samples_split=min_sample, random_state=0, criterion='entropy', n_jobs=3)\n",
    "\n",
    "def svm_model(C, gamma, name):\n",
    "    model = SVC(C=C, gamma=gamma, kernel=name)\n",
    "    return model\n",
    "\n",
    "def AdaBoost_model(base_estim, nb_estim, lr):\n",
    "    model = AdaBoostClassifier(base_estimator = DecisionTree_model(base_estim), n_estimators=nb_estim, learning_rate=lr, algorithm='SAMME.R', random_state=None)\n",
    "    return model\n",
    "\n",
    "def CNN_model(layers, perceptrons, epochs, learnRate):\n",
    "    \n",
    "    hiddenLayers = np.zeros((layers,), dtype=int)\n",
    "    for i in range(0, len(hiddenLayers)):\n",
    "        hiddenLayers[i] = perceptrons\n",
    "    \n",
    "    #Create model\n",
    "    model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=hiddenLayers, learning_rate_init=learnRate, \n",
    "                          max_iter=epochs, random_state=1)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def Ensemble_model():\n",
    "    model = VotingClassifier(estimators = [ ('DT', RandomForest_model(25, 10, 20)),\n",
    "                                           ('AB', AdaBoost_model(15, 50, 1.0)), \n",
    "                                           ('SVM', svm_model(10.0, 10.0, 'rbf')),\n",
    "                                           ('CNN', CNN_model(3, 120, 60, 0.001))], \n",
    "                                            voting = 'hard', n_jobs=3) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "    acc, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 10.0, 10.0)\n",
    "    return acc\n",
    "\n",
    "def SVM_linear(X_train, Y_train, X_val, Y_val, X_test, Y_test, C, gamma):   \n",
    "    print(\"svm_linear with C = \"+str(C)+\" and gamma = \"+str(gamma))\n",
    "    clf = SVC(C=C, gamma=gamma, kernel='linear')\n",
    "    clf.fit(X_train, np.ravel(Y_train))\n",
    "    \n",
    "    print(\"Start predictions...\")\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_val = clf.predict(X_val)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, pred_train], [Y_val, pred_val], [Y_test, pred_test]]\n",
    "    a1, f1 = GenerateScores(validations)\n",
    "    print(\"acc = \" + str(a1) + \", f1 = \" + str(f1))\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, C, gamma):   \n",
    "    clf = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(X_train, np.ravel(Y_train))\n",
    "    \n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_val = clf.predict(X_val)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, pred_train], [Y_val, pred_val], [Y_test, pred_test]]\n",
    "    a1, f1 = GenerateScores(validations)\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAccAndF1ToExcel(name, acc, f1, c_acc, c_f1):\n",
    "    acc_new = pd.DataFrame({'acc': acc})\n",
    "    f1_new = pd.DataFrame({'f1': f1})\n",
    "    wb = load_workbook(name)\n",
    "\n",
    "    ws = wb['Feuil1']\n",
    "\n",
    "    for index, row in acc_new.iterrows():\n",
    "        cell =  c_acc+'%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "        \n",
    "    for index, row in f1_new.iterrows():\n",
    "        cell = c_f1 + '%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "\n",
    "    wb.save(name)\n",
    "\n",
    "\n",
    "    return pd.read_excel(name, index_col=0)\n",
    "\n",
    "#svm = AddAccAndF1ToExcel('svm.xlsx', acc_svm, f1_svm, 'D', 'E')\n",
    "#rn_holdout = AddAccAndF1ToExcel('rn_holdout.xlsx', acc_neurone_holdout, f1_neurone_holdout, 'F', 'G')\n",
    "\n",
    "# For Debugging\n",
    "#print(acc_svm)\n",
    "#print(f1_svm)\n",
    "#print(acc_neurone_holdout)\n",
    "#print(f1_neurone_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ['BIG_BAND', 'BLUES_CONTEMPORARY', 'COUNTRY_TRADITIONAL', 'DANCE', 'ELECTRONICA', 'EXPERIMENTAL',\n",
    "          'FOLK_INTERNATIONAL', 'GOSPEL', 'GRUNGE_EMO', 'HIP_HOP_RAP', 'JAZZ_CLASSIC', 'METAL_ALTERNATIVE', \n",
    "          'METAL_DEATH', 'METAL_HEAVY', 'POP_CONTEMPORARY', 'POP_INDIE', 'POP_LATIN', 'PUNK', 'REGGAE','RNB_SOUL',\n",
    "          'ROCK_ALTERNATIVE', 'ROCK_COLLEGE', 'ROCK_CONTEMPORARY', 'ROCK_HARD', 'ROCK_NEO_PSYCHEDELIA']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Labels)\n",
    "\n",
    "def LabelsStrToInt(array):\n",
    "    return encoder.transform(array)\n",
    "\n",
    "def LabelsIntToStr(array):\n",
    "    return encoder.inverse_transform(array)\n",
    "\n",
    "def GetDataSet(name, nb, length):\n",
    "    fid = open(os.path.normpath('music/tagged_feature_sets/' + name + '/' + name + '.csv'), 'r') \n",
    "\n",
    "    ids = np.zeros((nb, 2), dtype=np.object)\n",
    "    primitives = np.zeros((nb, length), dtype=np.float64)\n",
    "    labels = np.zeros((nb, 1), dtype=np.object)\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "        \n",
    "        ids[count] = element[:2]\n",
    "        primitives[count] = element[2:-1]\n",
    "        labels[count] = element[-1:]\n",
    "\n",
    "        count += 1\n",
    "        if count >= nb:\n",
    "            break\n",
    "\n",
    "    fid.close()\n",
    "    \n",
    "    normalizedPrimitives = NormalizeData(primitives)\n",
    "\n",
    "    return ids, normalizedPrimitives, LabelsStrToInt(np.ravel(labels))\n",
    "\n",
    "# ----- For debug -----\n",
    "#print(count_smooth)\n",
    "#print(count_spiral)\n",
    "#print(count)\n",
    "#print(Galaxies)\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbData = 50000\n",
    "\n",
    "# id10, x10, y10 = GetDataSet('msd-mvd_dev', nbData, 420)\n",
    "# id9, x9, y9 = GetDataSet('msd-trh_dev', nbData, 420)\n",
    "# id8, x8, y8 = GetDataSet('msd-ssd_dev', nbData, 168)\n",
    "ids, x, y = GetDataSet('msd-marsyas_dev_new', nbData, 124)\n",
    "id6, x6, y6 = GetDataSet('msd-jmirderivatives_dev', nbData, 96)\n",
    "id5, x5, y5 = GetDataSet('msd-rh_dev_new', nbData, 60)\n",
    "#id4, x4, y4 = GetDataSet('msd-jmirmfccs_dev', nbData, 26)\n",
    "# id3, x3, y3 = GetDataSet('msd-jmirlpc_dev', nbData, 20)\n",
    "# id2, x2, y2 = GetDataSet('msd-jmirspectral_dev', nbData, 16)\n",
    "# id1, x1, y1 = GetDataSet('msd-jmirmoments_dev', nbData, 10)\n",
    "\n",
    "X_train, X_val, X_test = SplitVectorData_Holdout(x, 0.8)\n",
    "Y_train, Y_val, Y_test = SplitLabels_Holdout(y, 0.8)\n",
    "\n",
    "#----------For Debug-------------\n",
    "# print(id1[0])\n",
    "# print(x1[0])\n",
    "# print(y1[0])\n",
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_NB, f1_NB = GenerateScoresFromModel(x6, y6, GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_DT, f1_DT = GenerateScoresFromModel(x5, y5, DecisionTree_model(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_rbf with C = 10.0 and gamma = 10.0\n",
      "Start predictions...\n",
      "acc = [0.364075   0.25025005 0.25485097], f1 = [0.34914461 0.22817566 0.23620963]\n"
     ]
    }
   ],
   "source": [
    "acc_SVM, f1_SVM = GenerateScoresFromModel(x, y, svm_model(10.0, 10.0, 'rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_RF, f1_RF = GenerateScoresFromModel(x, y, RandomForest_model(25, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_CNN, f1_CNN = GenerateScoresFromModel(x, y, CNN_model(3, 120, 60, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_AB, f1_AB = GenerateScoresFromModel(x, y, AdaBoostClassifier(15, 50, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_VOTE, f1_VOTE = GenerateScoresFromModel(x, y, Ensemble_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1- Avec les liens fournis en l’annexe de cet énoncé et avec vos trouvailles faites sur Internet par le biais de vos recherches personnelles, faites, à titre d’introduction, une revue de la littérature. Expliquez en quelques paragraphes comment nous réussissons aujourd’hui à classifier différents sons et pièces musicales automatiquement afin de bien comprendre le sujet sur lequel vous travaillez. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2- Quelle est la configuration (machine, matériel, versions logiciel) de votre environnement? Quelle a été votre approche de partitionnement des données? Quels ensembles de primitives avez-vous choisis? Quelle méthode de validation avez-vous utilisée afin de confectionner vos modèles? Quelles étapes supplémentaires avez-vous eu à effectuer en prétraitement (normalisation, balancement, réduction de dimensionnalité, etc.)? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3- Quels sont les trois modèles d’apprentissage que vous avez décidé d’étudier à titre de classificateur de base? Exprimez les raisons qui vous ont mené à un tel choix. Si vous avez décidé d’implémenter un réseau de neurones, décrivez la structure de votre modèle d’apprentissage par réseau de neurones. Ajoutez tous graphiques ou représentation pertinente afin de décrire votre modèle, par exemple, un graphe TensorBoard si applicable ou un texte descriptif. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4- Pour vos trois modèles, présentez les hyperparamètres d’apprentissage et les ensembles de données utilisées ayant menés à votre meilleur résultat de précision (accuracy) et F-measure. Comment ces classificateurs ont-ils performés sur cet ensemble de données ? Discutez des résultats. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5- Présentez la conception de votre solution finale au problème (votre solution reposant sur la théorie des ensembles). Présentez ici le diagramme nécessaire afin de présenter convenablement votre combinaison de modèles, les ensembles de primitives choisies ainsi que la stratégie de combinaison. Faites une discussion expliquant vos décisions de conception. Faites des liens avec l’implémentation et présentez le code clé de celle-ci. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6- Consignez dans un tableau les hyperparamètres finaux de vos modèles faisant partie de votre ensemble. Présentez le score de précision (accuracy) et F1 final de votre ensemble. Présentez une discussion faisant l’analyse des résultats de votre système final. Décrivez les problèmes et difficultés rencontrées. Décrivez les performances de votre ensemble et tentez d’expliquer ces résultats. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Formulez quelques pistes d’amélioration de la solution développée.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
