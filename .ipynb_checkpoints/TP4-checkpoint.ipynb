{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTI770 - TP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import graphviz\n",
    "import decimal\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers as opt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from sklearn import tree\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from mdlp.discretization import MDLP\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility methods\n",
    "def SplitVectorData_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitVectorData_KFold(primitives_vector, k, test_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    subsetNb = int(size * (1 - test_portion) / k)\n",
    "    testNb = int(size * test_portion)\n",
    "    \n",
    "    array_kfold_train = np.zeros((k, subsetNb, subsize), dtype=np.float64)\n",
    "    array_kfold_test = np.zeros((testNb, subsize), dtype=np.float64)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        if i == 0 :\n",
    "            array_kfold_train[i] = primitives_vector[i * subsetNb]\n",
    "        else :\n",
    "            array_kfold_train[i] = primitives_vector[(i-1) * subsetNb : i * subsetNb]\n",
    "    \n",
    "    array_kfold_test = primitives_vector[-testNb:]\n",
    "\n",
    "    return array_kfold_train, array_kfold_test\n",
    "\n",
    "def SplitVectorData_NoVal(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    test_portion = (1 - train_portion)\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_test\n",
    "\n",
    "def concatenateWithoutTestPortion(full_array, index):\n",
    "    result_array = []\n",
    "    for i in range(0, len(full_array)):\n",
    "        if len(result_array) == 0:\n",
    "            result_array = full_array[i]\n",
    "        elif i != index :\n",
    "            result_array = np.concatenate((result_array, full_array[i]), axis=0)\n",
    "    return result_array\n",
    "\n",
    "def scores_mean(array_scores):\n",
    "    \n",
    "    size = len(array_scores)\n",
    "    subsize = len(array_scores[0])\n",
    "    array_mean = np.zeros(subsize, dtype=float)\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        for j in range(0, subsize):\n",
    "            array_mean[j] += array_scores[i][j]\n",
    "            \n",
    "    for j in range(0, subsize):\n",
    "            array_mean[j] = array_mean[j] / size\n",
    "    \n",
    "    return array_mean\n",
    "\n",
    "def UseModelOnTestData(array, model, transformer=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if transformer is not None:\n",
    "        transform_train, transform_val, transform_test, Y_train, Y_val, Y_test = TransformData(array_train, array_val, array_test, len(array_train[0]), transformer)\n",
    "    array_model_result, array_prediction_train_result, array_prediction_val_result, array_prediction_test_result, array_train_result, array_val_result, array_test_result = GenerateModelDataFromTransform(transform_train, transform_val, transform_test, Y_train, Y_val, Y_test, len(array[0]), model)\n",
    "    result = [[array_test_result, array_prediction_test_result]]\n",
    "    return GenerateScores(result) \n",
    "\n",
    "# ----- For debug -----\n",
    "#Filter_train, Filter_val, Filter_test = SplitVectorDataTrainValTest(Filter, 0.6)\n",
    "#print(len(Filter_train))\n",
    "#print(len(Filter_val))\n",
    "#print(len(Filter_test))\n",
    "#print(len(Filter))\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Models generation methods\n",
    "def GenerateModelDataFromVector(array_train, array_val, array_test, num_features, chosen_model):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    data_train = array_train\n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "    \n",
    "    data_val = array_val\n",
    "    X_val = data_val[:,0:num_features]\n",
    "    Y_val = data_val[:,num_features]\n",
    "    \n",
    "    data_test = array_test\n",
    "    X_test = data_test[:,0:num_features]\n",
    "    Y_test = data_test[:,num_features]\n",
    "    \n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    return model, prediction_train, prediction_val, prediction_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def TransformData(array_train, array_val, array_test, num_features, chosen_transformer):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    data_train = array_train\n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "    \n",
    "    data_val = array_val\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "    \n",
    "    data_test = array_test\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    \n",
    "    transformer_train = chosen_transformer\n",
    "    transformer_train = transformer_train.fit_transform(X_train, Y_train)\n",
    "    \n",
    "    transformer_val = chosen_transformer\n",
    "    transformer_val = transformer_val.fit_transform(X_val, Y_val)\n",
    "    \n",
    "    transformer_test = chosen_transformer\n",
    "    transformer_test = transformer_test.fit_transform(X_test, Y_test)\n",
    "    return transformer_train, transformer_val, transformer_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def GenerateModelDataFromTransform(array_train, array_val, array_test, y_train, y_val, y_test, num_features, chosen_model):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    X_train  = array_train\n",
    "    Y_train = y_train\n",
    "    \n",
    "    X_val = array_val\n",
    "    Y_val = y_val\n",
    "    \n",
    "    X_test  = array_test\n",
    "    Y_test = y_test\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    return model, prediction_train, prediction_val, prediction_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display methods\n",
    "def ExportTree(model):\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         #feature_names = ['', '', ''],  \n",
    "                         class_names = ['spam', 'mail'],\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render(\"Filter_data\") \n",
    "    return graph\n",
    "\n",
    "def GenerateScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "    F1Scores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "        F1Scores[i] = f1_score(array[i][0], array[i][1], average='weighted', labels=np.unique(array[i][1]))\n",
    "    \n",
    "    return AccScores, F1Scores\n",
    "\n",
    "def GenerateAccScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "    \n",
    "    return AccScores\n",
    "\n",
    "#Extraction de primitive\n",
    "def TracePlot(array_acc_X, array_acc_Y, array_f1_X, array_f1_Y, titre, titre_x, titre_y):        \n",
    "    \n",
    "    plt.plot(array_acc_X, array_acc_Y, 'ro')\n",
    "    plt.plot(array_f1_X, array_f1_Y, 'g*')\n",
    "    plt.xlabel(titre_x)\n",
    "    plt.ylabel(titre_y)\n",
    "    plt.legend(['Accuracy Score','F1 Score'])\n",
    "    plt.title(titre)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creations methods\n",
    "def CreateDecisionTreeModel(depth):\n",
    "    return tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth, min_samples_leaf=1)\n",
    "\n",
    "def CreateKNNModel(k, weight):\n",
    "    return KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "\n",
    "def CreateRandomForestModel(depth):\n",
    "    return RandomForestClassifier(criterion='entropy', max_depth=depth, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree methods\n",
    "def DecisionTree_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def DecisionTree_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bayes Methods\n",
    "def Bayes_Holdout(array, array_prob ,array_transform=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if array_transform is not None:\n",
    "        array_train_tr, array_val_tr, array_test_tr = SplitVectorData_Holdout(array_transform, 0.6)\n",
    "\n",
    "    transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "    transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "    if array_transform is not None:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "    else:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "\n",
    "    array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "    array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "    validations = [[array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10],\n",
    "    [array_val_mdlp, array_prediction_val_mdlp],\n",
    "    [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "    return GenerateScores(validations)  \n",
    "    \n",
    "def Bayes_KFold(array, array_prob, k, array_transform=None):\n",
    "    \n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    if array_transform is not None:\n",
    "        array_kfold_train_tr, array_kfold_test_tr = SplitVectorData_KFold(array_transform, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "        \n",
    "        if array_transform is not None:\n",
    "            array_train_tr = concatenateWithoutTestPortion(array_kfold_train_tr, i)\n",
    "            array_val_tr = array_kfold_train_tr[i]\n",
    "            array_test_tr = array_kfold_test_tr\n",
    "\n",
    "        transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "        transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "        if array_transform is not None:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        else:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "        array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "        validations = [[array_val_5, array_prediction_val_5],\n",
    "                     [array_val_10, array_prediction_val_10],\n",
    "                     [array_val_mdlp, array_prediction_val_mdlp],\n",
    "                     [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores \n",
    "        \n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "\n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Methods\n",
    "def KNN_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "    array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "    array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "    array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "    array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "    array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "    validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "                        [array_val_5u, array_prediction_val_5u],\n",
    "                        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "    validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "                        [array_val_5d, array_prediction_val_5d],\n",
    "                        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "    accScores_uniform, f1Scores_uniform = GenerateScores(validations_uniform)\n",
    "    accScores_distance, f1Scores_dsitance = GenerateScores(validations_distance)\n",
    "\n",
    "    return accScores_uniform, f1Scores_uniform, accScores_distance, f1Scores_dsitance\n",
    "    \n",
    "def KNN_KFold(array, k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_accScores_distance = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_distance = np.zeros((k, 3), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "        array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "        array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "        array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "        array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "        array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "        validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "        [array_val_5u, array_prediction_val_5u],\n",
    "        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "        validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "        [array_val_5d, array_prediction_val_5d],\n",
    "        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "        Array_AccScores_uniform, Array_F1Scores_uniform = GenerateScores(validations_uniform)\n",
    "        Array_AccScores_distance, Array_F1Scores_distance = GenerateScores(validations_distance)\n",
    "\n",
    "        all_accScores_uniform[i] = Array_AccScores_uniform\n",
    "        all_f1Scores_uniform[i] = Array_F1Scores_uniform\n",
    "        all_accScores_distance[i] = Array_AccScores_distance\n",
    "        all_f1Scores_distance[i] = Array_F1Scores_distance\n",
    "\n",
    "    accScores_mean_uniform = scores_mean(all_accScores_uniform)\n",
    "    f1Scores_mean_uniform = scores_mean(all_f1Scores_uniform)\n",
    "    accScores_mean_distance = scores_mean(all_accScores_distance)\n",
    "    f1Scores_mean_distance = scores_mean(all_f1Scores_distance)\n",
    "\n",
    "    return accScores_mean_uniform, f1Scores_mean_uniform, accScores_mean_distance, f1Scores_mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest methods\n",
    "def RandomForest_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def RandomForest_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accScores_filter_tree_holdout, f1Scores_filter_tree_holdout = DecisionTree_Holdout(Filter)\n",
    "# accScores_filter_tree_kfold, f1Scores_filter_tree_kfold = DecisionTree_KFold(Filter,10)\n",
    "# accScores_filter_bayes_holdout, f1Scores_filter_bayes_holdout = Bayes_Holdout(Filter, [0.4003,0.5997])\n",
    "# accScores_filter_bayes_kfold, f1Scores_filter_bayes_kfold = Bayes_KFold(Filter, [0.4003,0.5997], 10)\n",
    "# accScores_filter_knn_holdout_uniform, f1Scores_filter_knn_holdout_uniform, accScores_filter_knn_holdout_distance, f1Scores_filter_knn_holdout_distance = KNN_Holdout(Filter)\n",
    "# accScores_filter_knn_kfold_uniform, f1Scores_filter_knn_kfold_uniform, accScores_filter_knn_kfold_distance, f1Scores_filter_knn_kfold_distance = KNN_KFold(Filter, 10) \n",
    "# accScores_filter_test, f1Scores_filter_test = UseModelOnTestData(Filter, MultinomialNB(), MinMaxScaler())\n",
    "# accScores_filter_forest_holdout, f1Scores_filter_forest_holdout = RandomForest_Holdout(Filter)\n",
    "# accScores_filter_forest_kfold, f1Scores_filter_forest_kfold = RandomForest_KFold(Filter,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some galaxies\n",
    "fid = open('galaxy_feature_vectors.csv', 'r') \n",
    "\n",
    "NbGalaxy = 100 #16000 total\n",
    "Galaxies = np.zeros((NbGalaxy, 7), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "count_smooth = 0\n",
    "count_spiral = 0\n",
    "\n",
    "for line in fid:\n",
    "    element = line.rstrip('\\n').split(',')\n",
    "    \n",
    "    label = float(element[75])\n",
    "    \n",
    "    if label == 0.0 and count_smooth < NbGalaxy/2:\n",
    "        count_smooth += 1     \n",
    "    elif label == 1.0 and count_spiral < NbGalaxy/2:\n",
    "        count_spiral += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    Galaxies[count] = [element[4], element[5], element[6], element[17], element[23], element[24], element[75]]\n",
    "        \n",
    "    count += 1\n",
    "    if count >= NbGalaxy:\n",
    "        break\n",
    "\n",
    "fid.close() \n",
    "\n",
    "# ----- For debug -----\n",
    "#print(count_smooth)\n",
    "#print(count_spiral)\n",
    "#print(count)\n",
    "#print(Galaxies)\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    transform = MinMaxScaler()\n",
    "    return transform.fit_transform(data, data[:,len(Galaxies[0])-1])\n",
    "\n",
    "def GetGalaxiesClassProbabilities():\n",
    "    count_smooth = 0\n",
    "    count_spiral = 0\n",
    "    \n",
    "    fid = open('galaxy_feature_vectors.csv', 'r') \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "\n",
    "        label = float(element[75])\n",
    "\n",
    "        if label == 0.0:\n",
    "            count_smooth += 1     \n",
    "        elif label == 1.0:\n",
    "            count_spiral += 1\n",
    "    return [count_smooth/(count_smooth+count_spiral), count_spiral/(count_smooth+count_spiral)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SplitLabelsFromPrimitives(data_train, data_val, data_test):\n",
    "    num_features = len(data_train[0]) - 1\n",
    "    \n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "def GenerateModel(data_train, data_val, data_test, layers, perceptrons, epochs, learnRate, name):\n",
    "    \n",
    "    #Split labels from the primitives\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = SplitLabelsFromPrimitives(data_train, data_val, data_test)\n",
    "    \n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add layers\n",
    "    model.add(Dense(units=perceptrons, activation='sigmoid', input_shape=(len(X_train[0]),)))\n",
    "    model.add(Dropout(0.2))\n",
    "    for i in range(0, layers - 2):\n",
    "        model.add(Dense(units=perceptrons, activation='sigmoid'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=2, activation='sigmoid'))\n",
    "    \n",
    "    #Set optimizers and compile\n",
    "    sgd = opt.SGD(lr=learnRate, decay=0, momentum=0, nesterov=False)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Use TensorBoard\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/'+name)\n",
    "    \n",
    "    #Train\n",
    "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=100, callbacks=[tb_callback])\n",
    "    \n",
    "    model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    Y_probs = model.predict(X_test)\n",
    "    \n",
    "    Y_pred = Y_probs.argmax(axis=1)\n",
    "    \n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_pred)\n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test)\n",
    "\n",
    "    return Y_test, Y_pred\n",
    "\n",
    "def Neurone_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    \n",
    "    AccScores = np.zeros(13, dtype=float)\n",
    "    \n",
    "    #base\n",
    "    y_true_base, y_pred_base = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'base')\n",
    "    \n",
    "    #perceptrons\n",
    "    y_true_perc1, y_pred_perc1 = GenerateModel(array_train, array_val, array_test, 4, 50, 60, 0.5, 'perc1')\n",
    "    y_true_perc2, y_pred_perc2 = GenerateModel(array_train, array_val, array_test, 4, 300, 60, 0.5, 'perc2')\n",
    "    y_true_perc3, y_pred_perc3 = GenerateModel(array_train, array_val, array_test, 4, 600, 60, 0.5, 'perc3')\n",
    "\n",
    "    #epochs\n",
    "    y_true_epoch1, y_pred_epoch1 = GenerateModel(array_train, array_val, array_test, 4, 100, 30, 0.5, 'epoch1')\n",
    "    y_true_epoch2, y_pred_epoch2 = GenerateModel(array_train, array_val, array_test, 4, 100, 120, 0.5, 'epoch2')\n",
    "    y_true_epoch3, y_pred_epoch3 = GenerateModel(array_train, array_val, array_test, 4, 100, 240, 0.5, 'epoch3')\n",
    "    \n",
    "    #layers\n",
    "    y_true_layer1, y_pred_layer1 = GenerateModel(array_train, array_val, array_test, 6, 100, 60, 0.5, 'layer1')\n",
    "    y_true_layer2, y_pred_layer2 = GenerateModel(array_train, array_val, array_test, 12, 100, 60, 0.5, 'layer2')\n",
    "    y_true_layer3, y_pred_layer3 = GenerateModel(array_train, array_val, array_test, 24, 100, 60, 0.5, 'layer3')\n",
    "    \n",
    "    #learning rate\n",
    "    y_true_lr1, y_pred_lr1 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.1, 'lr1')\n",
    "    y_true_lr2, y_pred_lr2 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'lr2')\n",
    "    y_true_lr3, y_pred_lr3 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 1, 'lr3')\n",
    "\n",
    "    validations = [[y_true_base, y_pred_base],\n",
    "    [y_true_perc1, y_pred_perc1],\n",
    "    [y_true_perc2, y_pred_perc2],\n",
    "    [y_true_perc3, y_pred_perc3],\n",
    "    [y_true_epoch1, y_pred_epoch1],\n",
    "    [y_true_epoch2, y_pred_epoch2],\n",
    "    [y_true_epoch3, y_pred_epoch3],\n",
    "    [y_true_layer1, y_pred_layer1],\n",
    "    [y_true_layer2, y_pred_layer2],\n",
    "    [y_true_layer3, y_pred_layer3],\n",
    "    [y_true_lr1, y_pred_lr1],\n",
    "    [y_true_lr2, y_pred_lr2],\n",
    "    [y_true_lr3, y_pred_lr3]]\n",
    "    \n",
    "    return GenerateScores(validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7683 - acc: 0.4667 - val_loss: 0.6921 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6985 - acc: 0.4000 - val_loss: 0.6909 - val_acc: 0.5500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6933 - acc: 0.5333 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6881 - acc: 0.5500 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6952 - acc: 0.4833 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6952 - acc: 0.5500 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6833 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6975 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6828 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6952 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6824 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6750 - acc: 0.5833 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7066 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6837 - acc: 0.5667 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6833 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6983 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6857 - acc: 0.5667 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6934 - acc: 0.6167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7053 - acc: 0.5167 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6878 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6883 - acc: 0.5667 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7028 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6859 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6925 - acc: 0.5667 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6923 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6880 - acc: 0.5667 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6779 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6793 - acc: 0.5500 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6987 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6872 - acc: 0.5500 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6838 - acc: 0.5833 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6872 - acc: 0.4833 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.5333 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6948 - acc: 0.5333 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5500 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6956 - acc: 0.5000 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6900 - acc: 0.5000 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6910 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6980 - acc: 0.4667 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6872 - acc: 0.5167 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6902 - acc: 0.5000 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6954 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6982 - acc: 0.5167 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6944 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6859 - acc: 0.6333 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6972 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6884 - acc: 0.5167 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6907 - acc: 0.5167 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6782 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6839 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6925 - acc: 0.5333 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6983 - acc: 0.5333 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6883 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6985 - acc: 0.5167 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6936 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6991 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6954 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6898 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7004 - acc: 0.4333 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.6943 - acc: 0.5500 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6768 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6886 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6762 - acc: 0.6167 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6991 - acc: 0.5667 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6970 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7065 - acc: 0.4833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6914 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6910 - acc: 0.5167 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6862 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7002 - acc: 0.4833 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6862 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6874 - acc: 0.6000 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7060 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6983 - acc: 0.4667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6930 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6824 - acc: 0.6500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7158 - acc: 0.5333 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6796 - acc: 0.6000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6915 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6733 - acc: 0.6333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6827 - acc: 0.6333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7009 - acc: 0.6000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6893 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7080 - acc: 0.4333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6906 - acc: 0.4500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6872 - acc: 0.5833 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6930 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7050 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6898 - acc: 0.5167 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7064 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7020 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6944 - acc: 0.5500 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6974 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6966 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6889 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6932 - acc: 0.4333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6926 - acc: 0.5833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6888 - acc: 0.5833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6933 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7038 - acc: 0.4333 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6924 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6865 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6919 - acc: 0.6000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6939 - acc: 0.5500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6932 - acc: 0.5667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6962 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7011 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6998 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6989 - acc: 0.4333 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6913 - acc: 0.5667 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6996 - acc: 0.4833 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7035 - acc: 0.4833 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6849 - acc: 0.5500 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6924 - acc: 0.4500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6888 - acc: 0.5500 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6864 - acc: 0.5500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.4667 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7525 - acc: 0.4833 - val_loss: 1.7002 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 1.7722 - acc: 0.5333 - val_loss: 0.6940 - val_acc: 0.4500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6940 - val_acc: 0.4500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6940 - val_acc: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.4667 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6938 - acc: 0.4667 - val_loss: 0.6939 - val_acc: 0.4500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6948 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6942 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6939 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6940 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6942 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6939 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6937 - val_acc: 0.4500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6939 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6933 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6936 - val_acc: 0.4500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6938 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6938 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6933 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6933 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6929 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6934 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6936 - acc: 0.4667 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6933 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6937 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6935 - acc: 0.4667 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7081 - acc: 0.5500 - val_loss: 3.2899 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 3.4363 - acc: 0.5333 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6933 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 217us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6931 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 217us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6932 - acc: 0.4667 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/30\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7408 - acc: 0.4500 - val_loss: 0.7173 - val_acc: 0.5500\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7293 - acc: 0.5333 - val_loss: 0.7020 - val_acc: 0.4500\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7058 - acc: 0.4667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6912 - acc: 0.4833 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6887 - acc: 0.4833 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6911 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7017 - acc: 0.4833 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6736 - acc: 0.6167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7052 - acc: 0.4833 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6921 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7029 - acc: 0.5167 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7053 - acc: 0.4500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6860 - acc: 0.5667 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6975 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6884 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6942 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7118 - acc: 0.5167 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6896 - acc: 0.5667 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6974 - acc: 0.4833 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.4333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6964 - acc: 0.5667 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6851 - acc: 0.5833 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7000 - acc: 0.5167 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6994 - acc: 0.4333 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6973 - acc: 0.4000 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6922 - acc: 0.5333 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6900 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 0s 34us/step - loss: 0.6981 - acc: 0.5167 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/120\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.7857 - acc: 0.4833 - val_loss: 0.9488 - val_acc: 0.5500\n",
      "Epoch 2/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.9569 - acc: 0.5333 - val_loss: 0.7453 - val_acc: 0.4500\n",
      "Epoch 3/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7476 - acc: 0.4667 - val_loss: 0.7002 - val_acc: 0.4500\n",
      "Epoch 4/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7059 - acc: 0.4667 - val_loss: 0.6957 - val_acc: 0.4500\n",
      "Epoch 5/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6949 - acc: 0.5000 - val_loss: 0.6935 - val_acc: 0.4500\n",
      "Epoch 6/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6949 - acc: 0.4333 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 7/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6914 - acc: 0.5667 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 8/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6937 - acc: 0.5167 - val_loss: 0.6905 - val_acc: 0.5500\n",
      "Epoch 9/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 10/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6926 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 11/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6912 - acc: 0.5667 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 12/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6905 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 13/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7016 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 14/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6932 - acc: 0.5167 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 15/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6987 - acc: 0.5667 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 16/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6905 - acc: 0.5500 - val_loss: 0.6904 - val_acc: 0.5500\n",
      "Epoch 17/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6940 - acc: 0.4333 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 18/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6815 - acc: 0.6000 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 19/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6890 - acc: 0.5333 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 20/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6953 - acc: 0.4667 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 21/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6922 - acc: 0.5500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 22/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6999 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 23/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7012 - acc: 0.4833 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 24/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6902 - acc: 0.5167 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 25/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6896 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 26/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6968 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 27/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6909 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 28/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6854 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 29/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6960 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 30/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.5333 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 31/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6995 - acc: 0.5333 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 32/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6958 - acc: 0.5000 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 33/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6939 - acc: 0.5833 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 34/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.4833 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 35/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6965 - acc: 0.5500 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 36/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6963 - acc: 0.5500 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 37/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6899 - acc: 0.5667 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 38/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6960 - acc: 0.4667 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 39/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5500 - val_loss: 0.6894 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 41/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 42/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6854 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 43/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6863 - acc: 0.5167 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 44/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6905 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 45/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6950 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 46/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6889 - acc: 0.5667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 47/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6879 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 48/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6903 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 49/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6884 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 50/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6883 - acc: 0.5167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 51/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6886 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 52/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6956 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 53/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6902 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 54/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6907 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 55/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6952 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 56/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6952 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 57/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6894 - acc: 0.5167 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 58/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6889 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 59/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6957 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 60/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7012 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 61/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 62/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6981 - acc: 0.5167 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 63/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6861 - acc: 0.5333 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 64/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6956 - acc: 0.5167 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 65/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6876 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 66/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6920 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 67/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6899 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 68/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6937 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 69/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6852 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 70/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 71/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6902 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 72/120\n",
      "60/60 [==============================] - 0s 34us/step - loss: 0.6805 - acc: 0.5167 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 73/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6860 - acc: 0.5667 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 74/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 75/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6882 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 76/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7008 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 77/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6850 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 78/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6965 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 79/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6940 - acc: 0.5500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 80/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6886 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 81/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6777 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 82/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6857 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 83/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 84/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6950 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 85/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6958 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 86/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 87/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 88/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7013 - acc: 0.5500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 89/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7012 - acc: 0.5167 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 90/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6915 - acc: 0.5000 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 91/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6884 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 92/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6890 - acc: 0.5500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 93/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6938 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 94/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6992 - acc: 0.5000 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 95/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6901 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 96/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6914 - acc: 0.5333 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 97/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6920 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 98/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6909 - acc: 0.5167 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 99/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6902 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 100/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6923 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 101/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6957 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6926 - acc: 0.5333 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 103/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6866 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 104/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6880 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 105/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6946 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 106/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6912 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 107/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 108/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6836 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 109/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6894 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 110/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6901 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 111/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6853 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 112/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6920 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 113/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6992 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 114/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6920 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 115/120\n",
      "60/60 [==============================] - 0s 34us/step - loss: 0.6926 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 116/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6887 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 117/120\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6935 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 118/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6871 - acc: 0.5500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 119/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6841 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 120/120\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6835 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/240\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.6980 - acc: 0.5333 - val_loss: 0.6931 - val_acc: 0.5500\n",
      "Epoch 2/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6843 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 3/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7043 - acc: 0.4667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 4/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6921 - acc: 0.5167 - val_loss: 0.6907 - val_acc: 0.5500\n",
      "Epoch 5/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7102 - acc: 0.3667 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 6/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6965 - acc: 0.5500 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 7/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7105 - acc: 0.4500 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 8/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7041 - acc: 0.5167 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 9/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7010 - acc: 0.4000 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 10/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6810 - acc: 0.6167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 11/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6879 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 12/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7053 - acc: 0.4667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 13/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6810 - acc: 0.6167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 14/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7064 - acc: 0.5333 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 15/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6963 - acc: 0.4333 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 16/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6871 - acc: 0.5500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 17/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6804 - acc: 0.5667 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 18/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6847 - acc: 0.5500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 19/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6938 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 20/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6910 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 21/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6813 - acc: 0.5667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 22/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6899 - acc: 0.4333 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 23/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 24/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6905 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 25/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6770 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 26/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6712 - acc: 0.5500 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 27/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6810 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 28/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6705 - acc: 0.6000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 29/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6950 - acc: 0.6000 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 30/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6974 - acc: 0.5333 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 31/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6848 - acc: 0.5667 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 32/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7097 - acc: 0.5167 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 33/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6835 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 34/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.5833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 35/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7004 - acc: 0.4500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 36/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6807 - acc: 0.6000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 37/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6958 - acc: 0.4833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 38/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6822 - acc: 0.6000 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 39/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6831 - acc: 0.5167 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 40/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6879 - acc: 0.6000 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 41/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6978 - acc: 0.5000 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 42/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7191 - acc: 0.4333 - val_loss: 0.6888 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6801 - acc: 0.5667 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 44/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6938 - acc: 0.5833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 45/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7068 - acc: 0.4000 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 46/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6716 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 47/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6898 - acc: 0.4833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 48/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6879 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 49/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6747 - acc: 0.5167 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 50/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6832 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 51/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5833 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 52/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7005 - acc: 0.4667 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 53/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6820 - acc: 0.5500 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 54/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6947 - acc: 0.5500 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 55/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7003 - acc: 0.5167 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 56/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7004 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 57/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6948 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 58/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7052 - acc: 0.4000 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 59/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6882 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 60/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 61/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7033 - acc: 0.4667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 62/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6985 - acc: 0.4667 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 63/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6897 - acc: 0.5167 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 64/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6901 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 65/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6861 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 66/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6982 - acc: 0.5167 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 67/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7040 - acc: 0.4500 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 68/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6902 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 69/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6952 - acc: 0.4667 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 70/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6906 - acc: 0.4833 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 71/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6891 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 72/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6848 - acc: 0.5833 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 73/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6958 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 74/240\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6896 - acc: 0.6167 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 75/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6920 - acc: 0.5833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 76/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6850 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 77/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 78/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6807 - acc: 0.5500 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 79/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6711 - acc: 0.5333 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 80/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6982 - acc: 0.5167 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 81/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6981 - acc: 0.4667 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 82/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6965 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 83/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6931 - acc: 0.5333 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 84/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6898 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 85/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6850 - acc: 0.5833 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 86/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6838 - acc: 0.5333 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 87/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6909 - acc: 0.5167 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 88/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6850 - acc: 0.5333 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 89/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6897 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 90/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.5667 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 91/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6885 - acc: 0.5667 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 92/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6833 - acc: 0.5667 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 93/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6850 - acc: 0.5500 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 94/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6924 - acc: 0.4833 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 95/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6910 - acc: 0.5333 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 96/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5500 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 97/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7006 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 98/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6994 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 99/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6869 - acc: 0.5167 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 100/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6802 - acc: 0.5167 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 101/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6980 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 102/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.5167 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 103/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6909 - acc: 0.5333 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 104/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6878 - acc: 0.5167 - val_loss: 0.6879 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7016 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 106/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6894 - acc: 0.5333 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 107/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6940 - acc: 0.4833 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 108/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6952 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 109/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7014 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 110/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6861 - acc: 0.6333 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 111/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6913 - acc: 0.5333 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 112/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6847 - acc: 0.5333 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 113/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6930 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 114/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6882 - acc: 0.5833 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 115/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6875 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 116/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6815 - acc: 0.5000 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 117/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7012 - acc: 0.4833 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 118/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6963 - acc: 0.5333 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 119/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7052 - acc: 0.4833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 120/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6963 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 121/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6873 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 122/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 123/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6820 - acc: 0.6000 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 124/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6897 - acc: 0.5500 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 125/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6877 - acc: 0.5167 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 126/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6939 - acc: 0.5333 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 127/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6913 - acc: 0.5333 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 128/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7046 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 129/240\n",
      "60/60 [==============================] - 0s 34us/step - loss: 0.6898 - acc: 0.5167 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 130/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6859 - acc: 0.4833 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 131/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6889 - acc: 0.5667 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 132/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7103 - acc: 0.4833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 133/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6903 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 134/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6901 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 135/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6840 - acc: 0.5500 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 136/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6905 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 137/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6929 - acc: 0.4833 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 138/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6891 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 139/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6922 - acc: 0.4500 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 140/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6883 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 141/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6918 - acc: 0.5667 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 142/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6844 - acc: 0.5167 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 143/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6848 - acc: 0.5500 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 144/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6873 - acc: 0.5833 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 145/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6903 - acc: 0.5333 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 146/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6835 - acc: 0.5167 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 147/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6868 - acc: 0.4833 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 148/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6824 - acc: 0.5500 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 149/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6781 - acc: 0.5833 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 150/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6904 - acc: 0.5500 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 151/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6840 - acc: 0.5167 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 152/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6868 - acc: 0.5500 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 153/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6918 - acc: 0.5000 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 154/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.5500 - val_loss: 0.6870 - val_acc: 0.5500\n",
      "Epoch 155/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6890 - acc: 0.5333 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 156/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6892 - acc: 0.5167 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 157/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6889 - acc: 0.5500 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 158/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6842 - acc: 0.5833 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 159/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.5167 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 160/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.5167 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 161/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6815 - acc: 0.5667 - val_loss: 0.6874 - val_acc: 0.5500\n",
      "Epoch 162/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6866 - acc: 0.5500 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 163/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6947 - acc: 0.5000 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 164/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6996 - acc: 0.4833 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 165/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6948 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 166/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6884 - acc: 0.6000 - val_loss: 0.6877 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6965 - acc: 0.4833 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 168/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6919 - acc: 0.5167 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 169/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6843 - acc: 0.6000 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 170/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6959 - acc: 0.5000 - val_loss: 0.6876 - val_acc: 0.5500\n",
      "Epoch 171/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6845 - acc: 0.5833 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 172/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6882 - acc: 0.5500 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 173/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6943 - acc: 0.4833 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 174/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6922 - acc: 0.5667 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 175/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6906 - acc: 0.5833 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 176/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6922 - acc: 0.4833 - val_loss: 0.6872 - val_acc: 0.5500\n",
      "Epoch 177/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6774 - acc: 0.5667 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 178/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6937 - acc: 0.5167 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 179/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6887 - acc: 0.5500 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 180/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.5333 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 181/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6723 - acc: 0.5667 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 182/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6956 - acc: 0.5333 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 183/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6747 - acc: 0.5500 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 184/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6965 - acc: 0.5167 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 185/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6931 - acc: 0.5333 - val_loss: 0.6873 - val_acc: 0.5500\n",
      "Epoch 186/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5000 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 187/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6879 - acc: 0.5833 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 188/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6851 - acc: 0.5500 - val_loss: 0.6868 - val_acc: 0.5500\n",
      "Epoch 189/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6953 - acc: 0.4833 - val_loss: 0.6869 - val_acc: 0.5500\n",
      "Epoch 190/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6801 - acc: 0.5000 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 191/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6767 - acc: 0.5167 - val_loss: 0.6860 - val_acc: 0.5500\n",
      "Epoch 192/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6863 - acc: 0.5833 - val_loss: 0.6860 - val_acc: 0.5500\n",
      "Epoch 193/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6883 - acc: 0.5333 - val_loss: 0.6861 - val_acc: 0.5500\n",
      "Epoch 194/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 195/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6775 - acc: 0.5167 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 196/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6904 - acc: 0.5500 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 197/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6862 - acc: 0.5667 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 198/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6770 - acc: 0.5500 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 199/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6872 - acc: 0.5500 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 200/240\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6956 - acc: 0.5167 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 201/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6800 - acc: 0.5500 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 202/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6870 - acc: 0.6000 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 203/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6878 - acc: 0.5167 - val_loss: 0.6861 - val_acc: 0.5500\n",
      "Epoch 204/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6878 - acc: 0.5167 - val_loss: 0.6860 - val_acc: 0.5500\n",
      "Epoch 205/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6859 - acc: 0.5000 - val_loss: 0.6861 - val_acc: 0.5500\n",
      "Epoch 206/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6994 - acc: 0.5333 - val_loss: 0.6866 - val_acc: 0.5500\n",
      "Epoch 207/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6885 - acc: 0.5333 - val_loss: 0.6860 - val_acc: 0.5500\n",
      "Epoch 208/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6887 - acc: 0.5333 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 209/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6849 - acc: 0.5667 - val_loss: 0.6862 - val_acc: 0.5500\n",
      "Epoch 210/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6949 - acc: 0.5500 - val_loss: 0.6864 - val_acc: 0.5500\n",
      "Epoch 211/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6922 - acc: 0.5500 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 212/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6836 - acc: 0.5833 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 213/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6826 - acc: 0.5833 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 214/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6831 - acc: 0.6000 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 215/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6716 - acc: 0.6000 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 216/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6887 - acc: 0.5167 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 217/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6883 - acc: 0.4500 - val_loss: 0.6851 - val_acc: 0.5500\n",
      "Epoch 218/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6845 - acc: 0.5167 - val_loss: 0.6852 - val_acc: 0.5500\n",
      "Epoch 219/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6928 - acc: 0.5333 - val_loss: 0.6848 - val_acc: 0.5500\n",
      "Epoch 220/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6925 - acc: 0.4500 - val_loss: 0.6850 - val_acc: 0.5500\n",
      "Epoch 221/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7148 - acc: 0.5167 - val_loss: 0.6871 - val_acc: 0.5500\n",
      "Epoch 222/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6843 - acc: 0.5833 - val_loss: 0.6859 - val_acc: 0.5500\n",
      "Epoch 223/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6882 - acc: 0.5500 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 224/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6887 - acc: 0.6167 - val_loss: 0.6854 - val_acc: 0.5500\n",
      "Epoch 225/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6820 - acc: 0.5500 - val_loss: 0.6853 - val_acc: 0.5500\n",
      "Epoch 226/240\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6922 - acc: 0.5833 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 227/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6926 - acc: 0.4667 - val_loss: 0.6858 - val_acc: 0.5500\n",
      "Epoch 228/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6767 - acc: 0.6167 - val_loss: 0.6851 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6856 - val_acc: 0.5500\n",
      "Epoch 230/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6821 - acc: 0.5667 - val_loss: 0.6863 - val_acc: 0.5500\n",
      "Epoch 231/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7042 - acc: 0.5333 - val_loss: 0.6865 - val_acc: 0.5500\n",
      "Epoch 232/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6756 - acc: 0.5833 - val_loss: 0.6851 - val_acc: 0.5500\n",
      "Epoch 233/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6831 - acc: 0.6000 - val_loss: 0.6848 - val_acc: 0.5500\n",
      "Epoch 234/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6810 - acc: 0.5333 - val_loss: 0.6848 - val_acc: 0.5500\n",
      "Epoch 235/240\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7042 - acc: 0.5167 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 236/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6861 - acc: 0.5667 - val_loss: 0.6855 - val_acc: 0.5500\n",
      "Epoch 237/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6839 - acc: 0.5667 - val_loss: 0.6845 - val_acc: 0.5500\n",
      "Epoch 238/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6776 - acc: 0.5000 - val_loss: 0.6844 - val_acc: 0.5500\n",
      "Epoch 239/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6879 - acc: 0.5167 - val_loss: 0.6843 - val_acc: 0.5500\n",
      "Epoch 240/240\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6969 - acc: 0.5833 - val_loss: 0.6854 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 49us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.7154 - acc: 0.4833 - val_loss: 0.6951 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7041 - acc: 0.5333 - val_loss: 0.7079 - val_acc: 0.4500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.7155 - acc: 0.5000 - val_loss: 0.6977 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7232 - acc: 0.5167 - val_loss: 0.6940 - val_acc: 0.4500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7005 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6714 - acc: 0.5667 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7134 - acc: 0.5167 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.7006 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7173 - acc: 0.4500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6840 - acc: 0.5500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7011 - acc: 0.4833 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6706 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6845 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6938 - acc: 0.5167 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6864 - acc: 0.5167 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7109 - acc: 0.4500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6781 - acc: 0.5667 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.4667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7025 - acc: 0.5000 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7044 - acc: 0.4500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6944 - acc: 0.4833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6898 - acc: 0.5333 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7015 - acc: 0.4833 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.7002 - acc: 0.4667 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6949 - acc: 0.4500 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7012 - acc: 0.4667 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6889 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6872 - acc: 0.5667 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6882 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6892 - acc: 0.4667 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6959 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7061 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6918 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6945 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6892 - acc: 0.4667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6912 - acc: 0.5167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6918 - acc: 0.6333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6865 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6968 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.5500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6980 - acc: 0.4833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.4833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6931 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6972 - acc: 0.4833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6817 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6833 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6853 - acc: 0.5167 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6861 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6971 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6778 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6998 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6868 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 66us/step - loss: 0.6876 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6884 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6899 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.7038 - acc: 0.4833 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6998 - acc: 0.4500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6941 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 0us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.7042 - acc: 0.5333 - val_loss: 0.7008 - val_acc: 0.4500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6953 - acc: 0.5167 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6989 - acc: 0.5833 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7173 - acc: 0.4833 - val_loss: 0.6908 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6864 - acc: 0.5667 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7113 - acc: 0.4667 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7063 - acc: 0.4333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6811 - acc: 0.6167 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7033 - acc: 0.5167 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.7097 - acc: 0.3833 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6956 - acc: 0.4667 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7015 - acc: 0.4500 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7079 - acc: 0.4333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6913 - acc: 0.5667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6797 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.7007 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6886 - acc: 0.6167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7062 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7093 - acc: 0.4833 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6823 - acc: 0.5333 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6992 - acc: 0.4833 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6885 - acc: 0.5167 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6882 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6844 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6973 - acc: 0.5000 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6888 - acc: 0.4833 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6928 - acc: 0.5000 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6934 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6905 - acc: 0.5333 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6892 - acc: 0.5833 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6986 - acc: 0.4833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.7000 - acc: 0.5667 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6916 - acc: 0.5333 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6857 - acc: 0.6000 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7016 - acc: 0.4500 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6864 - acc: 0.5333 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6881 - acc: 0.5667 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6895 - acc: 0.5667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6976 - acc: 0.5167 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6986 - acc: 0.5000 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6846 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6873 - acc: 0.5333 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6906 - acc: 0.4667 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6913 - acc: 0.5333 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6980 - acc: 0.4667 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6838 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6978 - acc: 0.5667 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6917 - acc: 0.4833 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6870 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6833 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6894 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6929 - acc: 0.5167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6892 - acc: 0.5500 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6851 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.7008 - acc: 0.4500 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6871 - acc: 0.6333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6859 - acc: 0.5500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.6832 - acc: 0.5833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.6915 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.6880 - acc: 0.5667 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7265 - acc: 0.4833 - val_loss: 0.7081 - val_acc: 0.4500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.7290 - acc: 0.4000 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7071 - acc: 0.4833 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6875 - acc: 0.5667 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7100 - acc: 0.4500 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6929 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6887 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6886 - acc: 0.4833 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6931 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7076 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6829 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 166us/step - loss: 0.6964 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6821 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.7044 - acc: 0.5167 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6929 - acc: 0.5833 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6864 - acc: 0.4833 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6870 - acc: 0.6167 - val_loss: 0.6906 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6963 - acc: 0.5000 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.7078 - acc: 0.4167 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6950 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6855 - acc: 0.4500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6895 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 166us/step - loss: 0.6863 - acc: 0.5667 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6918 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6837 - acc: 0.6000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6918 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6901 - acc: 0.6167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7066 - acc: 0.4333 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6888 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6987 - acc: 0.5000 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6940 - acc: 0.5667 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6965 - acc: 0.5333 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6861 - acc: 0.5333 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6953 - acc: 0.5500 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6985 - acc: 0.4667 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7026 - acc: 0.4833 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6998 - acc: 0.4333 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6910 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6840 - acc: 0.5833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 166us/step - loss: 0.7028 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.7008 - acc: 0.4500 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6870 - acc: 0.5333 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 200us/step - loss: 0.6842 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6838 - acc: 0.5667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6952 - acc: 0.5500 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 166us/step - loss: 0.6873 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6854 - acc: 0.5167 - val_loss: 0.6894 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6964 - acc: 0.5167 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6826 - acc: 0.5833 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 166us/step - loss: 0.7022 - acc: 0.4667 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.6980 - acc: 0.5500 - val_loss: 0.6895 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6842 - acc: 0.6000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6941 - acc: 0.5167 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6954 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6839 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6946 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.6814 - acc: 0.5833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 167us/step - loss: 0.6946 - acc: 0.4500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 100us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.7761 - acc: 0.4833 - val_loss: 0.7085 - val_acc: 0.4500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7056 - acc: 0.4667 - val_loss: 0.6953 - val_acc: 0.4500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6987 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7000 - acc: 0.5000 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6478 - acc: 0.6333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7193 - acc: 0.4833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6802 - acc: 0.5167 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6893 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6804 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6687 - acc: 0.5833 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7000 - acc: 0.4667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7244 - acc: 0.4333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7111 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6874 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7402 - acc: 0.4667 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6778 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7045 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6988 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6950 - acc: 0.4833 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.7309 - acc: 0.4833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6716 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6981 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7300 - acc: 0.4667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6916 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7144 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6915 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6973 - acc: 0.5167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6764 - acc: 0.5833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7269 - acc: 0.4000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6619 - acc: 0.5833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7136 - acc: 0.5167 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6993 - acc: 0.4833 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6767 - acc: 0.5833 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7112 - acc: 0.5333 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7111 - acc: 0.5167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7105 - acc: 0.4667 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6881 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6617 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6965 - acc: 0.5667 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6987 - acc: 0.4667 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6701 - acc: 0.6000 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7042 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7097 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7038 - acc: 0.4667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6907 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6895 - acc: 0.5500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7051 - acc: 0.5000 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7088 - acc: 0.4667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7051 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 34us/step - loss: 0.7076 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6927 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6852 - acc: 0.6000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6668 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7076 - acc: 0.4833 - val_loss: 0.6886 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6748 - acc: 0.6000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6929 - acc: 0.5667 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6777 - acc: 0.5833 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7109 - acc: 0.5500 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7043 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 49us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 0.6894 - acc: 0.5500 - val_loss: 0.7059 - val_acc: 0.4500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7368 - acc: 0.4667 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7067 - acc: 0.4833 - val_loss: 0.6935 - val_acc: 0.4000\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6907 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6949 - acc: 0.4500 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6826 - acc: 0.5667 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6823 - acc: 0.5667 - val_loss: 0.6952 - val_acc: 0.4500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6780 - acc: 0.5333 - val_loss: 0.6915 - val_acc: 0.5500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7083 - acc: 0.4000 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.5333 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7095 - acc: 0.4500 - val_loss: 0.6899 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6869 - acc: 0.5167 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7226 - acc: 0.4000 - val_loss: 0.6914 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6897 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7022 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7087 - acc: 0.4167 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7124 - acc: 0.4667 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6876 - acc: 0.6167 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6920 - acc: 0.5000 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6950 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6919 - acc: 0.6000 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6956 - acc: 0.5167 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6896 - acc: 0.4667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6995 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7097 - acc: 0.4333 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6922 - acc: 0.5333 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6960 - acc: 0.5000 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7014 - acc: 0.4500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.7000 - acc: 0.5500 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6815 - acc: 0.4833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6870 - acc: 0.5833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6916 - acc: 0.5167 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6975 - acc: 0.5167 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6992 - acc: 0.4500 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6894 - acc: 0.5167 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6906 - acc: 0.5833 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6907 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6844 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6846 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6905 - acc: 0.5667 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6890 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6930 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6737 - acc: 0.5667 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6816 - acc: 0.5167 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6973 - acc: 0.5167 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6959 - acc: 0.4667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6828 - acc: 0.5333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6870 - acc: 0.5667 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6943 - acc: 0.5000 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6958 - acc: 0.5333 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6961 - acc: 0.5167 - val_loss: 0.6893 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6962 - acc: 0.4667 - val_loss: 0.6892 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6854 - acc: 0.5667 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6871 - acc: 0.5500 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6866 - acc: 0.5667 - val_loss: 0.6881 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6748 - acc: 0.5667 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6851 - acc: 0.5667 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6934 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n",
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/60\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6725 - acc: 0.5833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 2/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6885 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 3/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6999 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 4/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6925 - acc: 0.5000 - val_loss: 0.6898 - val_acc: 0.5500\n",
      "Epoch 5/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6909 - acc: 0.5167 - val_loss: 0.6903 - val_acc: 0.5500\n",
      "Epoch 6/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6743 - acc: 0.6333 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 7/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6900 - acc: 0.5333 - val_loss: 0.6928 - val_acc: 0.5500\n",
      "Epoch 8/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6976 - acc: 0.4333 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 9/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6939 - acc: 0.5333 - val_loss: 0.6934 - val_acc: 0.4500\n",
      "Epoch 10/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6983 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 11/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7134 - acc: 0.5333 - val_loss: 0.6938 - val_acc: 0.4500\n",
      "Epoch 12/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6931 - acc: 0.4833 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 13/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6948 - acc: 0.5833 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 14/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6737 - acc: 0.5500 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 15/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6995 - acc: 0.5167 - val_loss: 0.6902 - val_acc: 0.5500\n",
      "Epoch 16/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.7105 - acc: 0.4167 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 17/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6863 - acc: 0.5500 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 18/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6959 - acc: 0.4833 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 19/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6913 - acc: 0.5500 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 20/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6978 - acc: 0.5500 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 21/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6919 - acc: 0.5000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 22/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6932 - acc: 0.5500 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 23/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6862 - acc: 0.5333 - val_loss: 0.6886 - val_acc: 0.5500\n",
      "Epoch 24/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6852 - acc: 0.6000 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 25/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6888 - acc: 0.4833 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 26/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6895 - acc: 0.5667 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "Epoch 27/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6968 - acc: 0.5167 - val_loss: 0.6882 - val_acc: 0.5500\n",
      "Epoch 28/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6861 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 29/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6929 - acc: 0.5000 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 30/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6892 - acc: 0.5833 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 31/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6843 - acc: 0.5500 - val_loss: 0.6877 - val_acc: 0.5500\n",
      "Epoch 32/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6947 - acc: 0.5333 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 33/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6871 - acc: 0.5333 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 34/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6944 - acc: 0.5167 - val_loss: 0.6910 - val_acc: 0.5500\n",
      "Epoch 35/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6964 - acc: 0.4833 - val_loss: 0.6901 - val_acc: 0.5500\n",
      "Epoch 36/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6914 - acc: 0.5333 - val_loss: 0.6888 - val_acc: 0.5500\n",
      "Epoch 37/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6891 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 38/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6936 - acc: 0.5167 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 39/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6958 - acc: 0.5167 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 40/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6941 - acc: 0.4833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 41/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6984 - acc: 0.4833 - val_loss: 0.6896 - val_acc: 0.5500\n",
      "Epoch 42/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6898 - acc: 0.5667 - val_loss: 0.6887 - val_acc: 0.5500\n",
      "Epoch 43/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6904 - acc: 0.5667 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 44/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6931 - acc: 0.5500 - val_loss: 0.6895 - val_acc: 0.5500\n",
      "Epoch 45/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6983 - acc: 0.5667 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 46/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6954 - acc: 0.4833 - val_loss: 0.6890 - val_acc: 0.5500\n",
      "Epoch 47/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6890 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 48/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6887 - acc: 0.4833 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 49/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6940 - acc: 0.5000 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 50/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6898 - acc: 0.5333 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 51/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6915 - acc: 0.5667 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 52/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6872 - acc: 0.5500 - val_loss: 0.6889 - val_acc: 0.5500\n",
      "Epoch 53/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6808 - acc: 0.5667 - val_loss: 0.6878 - val_acc: 0.5500\n",
      "Epoch 54/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.5000 - val_loss: 0.6880 - val_acc: 0.5500\n",
      "Epoch 55/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6850 - acc: 0.5500 - val_loss: 0.6883 - val_acc: 0.5500\n",
      "Epoch 56/60\n",
      "60/60 [==============================] - 0s 33us/step - loss: 0.6830 - acc: 0.5333 - val_loss: 0.6875 - val_acc: 0.5500\n",
      "Epoch 57/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6980 - acc: 0.5000 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 58/60\n",
      "60/60 [==============================] - 0s 67us/step - loss: 0.6875 - acc: 0.4833 - val_loss: 0.6885 - val_acc: 0.5500\n",
      "Epoch 59/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6839 - acc: 0.5500 - val_loss: 0.6875 - val_acc: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "60/60 [==============================] - 0s 50us/step - loss: 0.6903 - acc: 0.5667 - val_loss: 0.6879 - val_acc: 0.5500\n",
      "20/20 [==============================] - 0s 50us/step\n"
     ]
    }
   ],
   "source": [
    "# Galaxies_norm = NormalizeData(Galaxies)\n",
    "acc_neurone_holdout, f1_neurone_holdout = Neurone_Holdout(Galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35, 0.35, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35,\n",
       "       0.35, 0.35])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_neurone_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_linear(X_train, Y_train, X_test, C):\n",
    "    gamma_range = np.logspace(-9, 3, 13)\n",
    "    param_grid = dict(gamma=gamma_range)\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(cache_size=2048), param_grid=param_grid, cv=cv, n_jobs=4)\n",
    "    grid.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "    clf = SVC(C=C, gamma=grid.best_params_['gamma'], class_weight='balanced', kernel='linear')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def SVM_rbf(X_train, Y_train, X_test, C, gamma):\n",
    "\n",
    "    clf = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def SVM(array):\n",
    "    array_train, array_test = SplitVectorData_NoVal(array, 0.8)\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = SplitLabelsFromPrimitives(array_train, array_test, array_test) #Val N,est pas utilisé, mais la méthode èa besoin du paremèetre. On lui passe donc les données tests.\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    Y_pred_lin03= SVM_linear(X_train, Y_train, X_test, 1e-03)\n",
    "    Y_pred_lin01= SVM_linear(X_train, Y_train, X_test, 1e-01)\n",
    "    Y_pred_lin1= SVM_linear(X_train, Y_train, X_test, 1.0)\n",
    "    Y_pred_lin10= SVM_linear(X_train, Y_train, X_test, 10.0)\n",
    "    Y_pred_rbf03_g03= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-03)\n",
    "    Y_pred_rbf01_g03= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-03)\n",
    "    Y_pred_rbf1_g03= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-03)\n",
    "    Y_pred_rbf10_g03= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-03)\n",
    "    Y_pred_rbf03_g01= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-01)\n",
    "    Y_pred_rbf01_g01= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-01)\n",
    "    Y_pred_rbf1_g01= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-01)\n",
    "    Y_pred_rbf10_g01= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-01)\n",
    "    Y_pred_rbf03_g1= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1.0)\n",
    "    Y_pred_rbf01_g1= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1.0)\n",
    "    Y_pred_rbf1_g1= SVM_rbf(X_train, Y_train, X_test, 1.0, 1.0)\n",
    "    Y_pred_rbf10_g1= SVM_rbf(X_train, Y_train, X_test, 10.0, 1.0)\n",
    "    Y_pred_rbf03_g10= SVM_rbf(X_train, Y_train, X_test, 1e-03, 10.0)\n",
    "    Y_pred_rbf01_g10= SVM_rbf(X_train, Y_train, X_test, 1e-01, 10.0)\n",
    "    Y_pred_rbf1_g10= SVM_rbf(X_train, Y_train, X_test, 1.0, 10.0)\n",
    "    Y_pred_rbf10_g10= SVM_rbf(X_train, Y_train, X_test, 10.0, 10.0)\n",
    "    \n",
    "    validations = [[Y_test, Y_pred_lin03],\n",
    "    [Y_test, Y_pred_lin01],\n",
    "    [Y_test, Y_pred_lin1],\n",
    "    [Y_test, Y_pred_lin10],             \n",
    "    [Y_test, Y_pred_rbf03_g03],\n",
    "    [Y_test, Y_pred_rbf01_g03],\n",
    "    [Y_test, Y_pred_rbf1_g03],\n",
    "    [Y_test, Y_pred_rbf10_g03],            \n",
    "    [Y_test, Y_pred_rbf03_g01],\n",
    "    [Y_test, Y_pred_rbf01_g01],\n",
    "    [Y_test, Y_pred_rbf1_g01],\n",
    "    [Y_test, Y_pred_rbf10_g01],              \n",
    "    [Y_test, Y_pred_rbf03_g1],\n",
    "    [Y_test, Y_pred_rbf01_g1],\n",
    "    [Y_test, Y_pred_rbf1_g1],\n",
    "    [Y_test, Y_pred_rbf10_g1],            \n",
    "    [Y_test, Y_pred_rbf03_g10],\n",
    "    [Y_test, Y_pred_rbf01_g10],\n",
    "    [Y_test, Y_pred_rbf1_g10],\n",
    "    [Y_test, Y_pred_rbf10_g10]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'gamma': 1.0} with a score of 0.72\n",
      "The best parameters are {'gamma': 1.0} with a score of 0.72\n",
      "The best parameters are {'gamma': 1.0} with a score of 0.72\n",
      "The best parameters are {'gamma': 1.0} with a score of 0.72\n"
     ]
    }
   ],
   "source": [
    "acc_svm, f1_svm = SVM(Galaxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Debugging\n",
    "#print(acc_svm)\n",
    "#print(f1_svm)\n",
    "#print(acc_neurone_holdout)\n",
    "#print(f1_neurone_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAccAndF1ToExcel(name, acc, f1, c_acc, c_f1):\n",
    "    acc_new = pd.DataFrame({'acc': acc})\n",
    "    f1_new = pd.DataFrame({'f1': f1})\n",
    "    wb = load_workbook(name)\n",
    "\n",
    "    ws = wb['Feuil1']\n",
    "\n",
    "    for index, row in acc_new.iterrows():\n",
    "        cell =  c_acc+'%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "        \n",
    "    for index, row in f1_new.iterrows():\n",
    "        cell = c_f1 + '%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "\n",
    "    wb.save(name)\n",
    "\n",
    "\n",
    "    return pd.read_excel(name, index_col=0)\n",
    "\n",
    "svm = AddAccAndF1ToExcel('svm.xlsx', acc_svm, f1_svm, 'D', 'E')\n",
    "rn_holdout = AddAccAndF1ToExcel('rn_holdout.xlsx', acc_neurone_holdout, f1_neurone_holdout, 'F', 'G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
