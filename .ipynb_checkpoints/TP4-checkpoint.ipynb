{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GTI770 - TP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import graphviz\n",
    "import decimal\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers as opt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mdlp.discretization import MDLP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility methods\n",
    "def SplitVectorData_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitLabels_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = 1\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitVectorData_KFold(primitives_vector, k, test_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    subsetNb = int(size * (1 - test_portion) / k)\n",
    "    testNb = int(size * test_portion)\n",
    "    \n",
    "    array_kfold_train = np.zeros((k, subsetNb, subsize), dtype=np.float64)\n",
    "    array_kfold_test = np.zeros((testNb, subsize), dtype=np.float64)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        if i == 0 :\n",
    "            array_kfold_train[i] = primitives_vector[i * subsetNb]\n",
    "        else :\n",
    "            array_kfold_train[i] = primitives_vector[(i-1) * subsetNb : i * subsetNb]\n",
    "    \n",
    "    array_kfold_test = primitives_vector[-testNb:]\n",
    "\n",
    "    return array_kfold_train, array_kfold_test\n",
    "\n",
    "def SplitVectorData_NoVal(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    test_portion = (1 - train_portion)\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_test\n",
    "\n",
    "def concatenateWithoutTestPortion(full_array, index):\n",
    "    result_array = []\n",
    "    for i in range(0, len(full_array)):\n",
    "        if len(result_array) == 0:\n",
    "            result_array = full_array[i]\n",
    "        elif i != index :\n",
    "            result_array = np.concatenate((result_array, full_array[i]), axis=0)\n",
    "    return result_array\n",
    "\n",
    "def scores_mean(array_scores):\n",
    "    \n",
    "    size = len(array_scores)\n",
    "    subsize = len(array_scores[0])\n",
    "    array_mean = np.zeros(subsize, dtype=float)\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        for j in range(0, subsize):\n",
    "            array_mean[j] += array_scores[i][j]\n",
    "            \n",
    "    for j in range(0, subsize):\n",
    "            array_mean[j] = array_mean[j] / size\n",
    "    \n",
    "    return array_mean\n",
    "\n",
    "def UseModelOnTestData(array, model, transformer=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if transformer is not None:\n",
    "        transform_train, transform_val, transform_test, Y_train, Y_val, Y_test = TransformData(array_train, array_val, array_test, len(array_train[0]), transformer)\n",
    "    array_model_result, array_prediction_train_result, array_prediction_val_result, array_prediction_test_result, array_train_result, array_val_result, array_test_result = GenerateModelDataFromTransform(transform_train, transform_val, transform_test, Y_train, Y_val, Y_test, len(array[0]), model)\n",
    "    result = [[array_test_result, array_prediction_test_result]]\n",
    "    return GenerateScores(result) \n",
    "\n",
    "# ----- For debug -----\n",
    "#Filter_train, Filter_val, Filter_test = SplitVectorDataTrainValTest(Filter, 0.6)\n",
    "#print(len(Filter_train))\n",
    "#print(len(Filter_val))\n",
    "#print(len(Filter_test))\n",
    "#print(len(Filter))\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Models generation methods\n",
    "\n",
    "def GenerateModelDataFromVector(x, y, chosen_model):\n",
    "    \n",
    "    X_train, X_val, X_test = SplitVectorData_Holdout(x, 0.8)\n",
    "    Y_train, Y_val, Y_test = SplitLabels_Holdout(y, 0.8)\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, prediction_train], [Y_val, prediction_val], [Y_test, prediction_test]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def TransformData(array_train, array_val, array_test, num_features, chosen_transformer):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    data_train = array_train\n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "    \n",
    "    data_val = array_val\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "    \n",
    "    data_test = array_test\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    \n",
    "    transformer_train = chosen_transformer\n",
    "    transformer_train = transformer_train.fit_transform(X_train, Y_train)\n",
    "    \n",
    "    transformer_val = chosen_transformer\n",
    "    transformer_val = transformer_val.fit_transform(X_val, Y_val)\n",
    "    \n",
    "    transformer_test = chosen_transformer\n",
    "    transformer_test = transformer_test.fit_transform(X_test, Y_test)\n",
    "    return transformer_train, transformer_val, transformer_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def GenerateModelDataFromTransform(array_train, array_val, array_test, y_train, y_val, y_test, num_features, chosen_model):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    X_train  = array_train\n",
    "    Y_train = y_train\n",
    "    \n",
    "    X_val = array_val\n",
    "    Y_val = y_val\n",
    "    \n",
    "    X_test  = array_test\n",
    "    Y_test = y_test\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    return model, prediction_train, prediction_val, prediction_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display methods\n",
    "def ExportTree(model):\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         #feature_names = ['', '', ''],  \n",
    "                         class_names = ['spam', 'mail'],\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render(\"Filter_data\") \n",
    "    return graph\n",
    "\n",
    "def GenerateScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "    F1Scores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "        F1Scores[i] = f1_score(array[i][0], array[i][1], average='weighted', labels=np.unique(array[i][1]))\n",
    "    \n",
    "    return AccScores, F1Scores\n",
    "\n",
    "def GenerateAccScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "    \n",
    "    return AccScores\n",
    "\n",
    "#Extraction de primitive\n",
    "def TracePlot(array_acc_X, array_acc_Y, array_f1_X, array_f1_Y, titre, titre_x, titre_y):        \n",
    "    \n",
    "    plt.plot(array_acc_X, array_acc_Y, 'ro')\n",
    "    plt.plot(array_f1_X, array_f1_Y, 'g*')\n",
    "    plt.xlabel(titre_x)\n",
    "    plt.ylabel(titre_y)\n",
    "    plt.legend(['Accuracy Score','F1 Score'])\n",
    "    plt.title(titre)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creations methods\n",
    "def CreateDecisionTreeModel(depth):\n",
    "    return tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth, min_samples_leaf=1)\n",
    "\n",
    "def CreateKNNModel(k, weight):\n",
    "    return KNeighborsClassifier(n_neighbors=k, weights=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree methods\n",
    "def DecisionTree_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def DecisionTree_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bayes Methods\n",
    "def Bayes_Holdout(array, array_prob ,array_transform=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if array_transform is not None:\n",
    "        array_train_tr, array_val_tr, array_test_tr = SplitVectorData_Holdout(array_transform, 0.6)\n",
    "\n",
    "    transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "    transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "    if array_transform is not None:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "    else:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "\n",
    "    array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "    array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "    validations = [[array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10],\n",
    "    [array_val_mdlp, array_prediction_val_mdlp],\n",
    "    [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "    return GenerateScores(validations)  \n",
    "    \n",
    "def Bayes_KFold(array, array_prob, k, array_transform=None):\n",
    "    \n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    if array_transform is not None:\n",
    "        array_kfold_train_tr, array_kfold_test_tr = SplitVectorData_KFold(array_transform, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "        \n",
    "        if array_transform is not None:\n",
    "            array_train_tr = concatenateWithoutTestPortion(array_kfold_train_tr, i)\n",
    "            array_val_tr = array_kfold_train_tr[i]\n",
    "            array_test_tr = array_kfold_test_tr\n",
    "\n",
    "        transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "        transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "        if array_transform is not None:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        else:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "        array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "        validations = [[array_val_5, array_prediction_val_5],\n",
    "                     [array_val_10, array_prediction_val_10],\n",
    "                     [array_val_mdlp, array_prediction_val_mdlp],\n",
    "                     [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores \n",
    "        \n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "\n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Methods\n",
    "def KNN_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "    array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "    array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "    array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "    array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "    array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "    validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "                        [array_val_5u, array_prediction_val_5u],\n",
    "                        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "    validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "                        [array_val_5d, array_prediction_val_5d],\n",
    "                        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "    accScores_uniform, f1Scores_uniform = GenerateScores(validations_uniform)\n",
    "    accScores_distance, f1Scores_dsitance = GenerateScores(validations_distance)\n",
    "\n",
    "    return accScores_uniform, f1Scores_uniform, accScores_distance, f1Scores_dsitance\n",
    "    \n",
    "def KNN_KFold(array, k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_accScores_distance = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_distance = np.zeros((k, 3), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "        array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "        array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "        array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "        array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "        array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "        validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "        [array_val_5u, array_prediction_val_5u],\n",
    "        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "        validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "        [array_val_5d, array_prediction_val_5d],\n",
    "        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "        Array_AccScores_uniform, Array_F1Scores_uniform = GenerateScores(validations_uniform)\n",
    "        Array_AccScores_distance, Array_F1Scores_distance = GenerateScores(validations_distance)\n",
    "\n",
    "        all_accScores_uniform[i] = Array_AccScores_uniform\n",
    "        all_f1Scores_uniform[i] = Array_F1Scores_uniform\n",
    "        all_accScores_distance[i] = Array_AccScores_distance\n",
    "        all_f1Scores_distance[i] = Array_F1Scores_distance\n",
    "\n",
    "    accScores_mean_uniform = scores_mean(all_accScores_uniform)\n",
    "    f1Scores_mean_uniform = scores_mean(all_f1Scores_uniform)\n",
    "    accScores_mean_distance = scores_mean(all_accScores_distance)\n",
    "    f1Scores_mean_distance = scores_mean(all_f1Scores_distance)\n",
    "\n",
    "    return accScores_mean_uniform, f1Scores_mean_uniform, accScores_mean_distance, f1Scores_mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest methods\n",
    "def RandomForest_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def RandomForest_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return MinMaxScaler().fit_transform(data)\n",
    "\n",
    "def GetGalaxiesClassProbabilities():\n",
    "    count_smooth = 0\n",
    "    count_spiral = 0\n",
    "    \n",
    "    fid = open('galaxy_feature_vectors.csv', 'r') \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "\n",
    "        label = float(element[75])\n",
    "\n",
    "        if label == 0.0:\n",
    "            count_smooth += 1     \n",
    "        elif label == 1.0:\n",
    "            count_spiral += 1\n",
    "    return [count_smooth/(count_smooth+count_spiral), count_spiral/(count_smooth+count_spiral)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SplitLabelsFromPrimitives(data_train, data_val, data_test):\n",
    "    num_features = len(data_train[0]) - 1\n",
    "    \n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "def GenerateModel(data_train, data_val, data_test, layers, perceptrons, epochs, learnRate, name):\n",
    "    \n",
    "    #Split labels from the primitives\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = SplitLabelsFromPrimitives(data_train, data_val, data_test)\n",
    "    \n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add layers\n",
    "    model.add(Dense(units=perceptrons, activation='sigmoid', input_shape=(len(X_train[0]),)))\n",
    "    model.add(Dropout(0.2))\n",
    "    for i in range(0, layers - 2):\n",
    "        model.add(Dense(units=perceptrons, activation='sigmoid'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=2, activation='sigmoid'))\n",
    "    \n",
    "    #Set optimizers and compile\n",
    "    sgd = opt.SGD(lr=learnRate, decay=0, momentum=0, nesterov=False)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Use TensorBoard\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/'+name)\n",
    "    \n",
    "    #Train\n",
    "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=100, callbacks=[tb_callback])\n",
    "    \n",
    "    model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    Y_probs = model.predict(X_test)\n",
    "    \n",
    "    Y_pred = Y_probs.argmax(axis=1)\n",
    "    \n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_pred)\n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test)\n",
    "\n",
    "    return Y_test, Y_pred\n",
    "\n",
    "def Neurone_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    \n",
    "    AccScores = np.zeros(13, dtype=float)\n",
    "    \n",
    "    #base\n",
    "    y_true_base, y_pred_base = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'base')\n",
    "    \n",
    "    #perceptrons\n",
    "    y_true_perc1, y_pred_perc1 = GenerateModel(array_train, array_val, array_test, 4, 50, 60, 0.5, 'perc1')\n",
    "    y_true_perc2, y_pred_perc2 = GenerateModel(array_train, array_val, array_test, 4, 300, 60, 0.5, 'perc2')\n",
    "    y_true_perc3, y_pred_perc3 = GenerateModel(array_train, array_val, array_test, 4, 600, 60, 0.5, 'perc3')\n",
    "\n",
    "    #epochs\n",
    "    y_true_epoch1, y_pred_epoch1 = GenerateModel(array_train, array_val, array_test, 4, 100, 30, 0.5, 'epoch1')\n",
    "    y_true_epoch2, y_pred_epoch2 = GenerateModel(array_train, array_val, array_test, 4, 100, 120, 0.5, 'epoch2')\n",
    "    y_true_epoch3, y_pred_epoch3 = GenerateModel(array_train, array_val, array_test, 4, 100, 240, 0.5, 'epoch3')\n",
    "    \n",
    "    #layers\n",
    "    y_true_layer1, y_pred_layer1 = GenerateModel(array_train, array_val, array_test, 6, 100, 60, 0.5, 'layer1')\n",
    "    y_true_layer2, y_pred_layer2 = GenerateModel(array_train, array_val, array_test, 12, 100, 60, 0.5, 'layer2')\n",
    "    y_true_layer3, y_pred_layer3 = GenerateModel(array_train, array_val, array_test, 24, 100, 60, 0.5, 'layer3')\n",
    "    \n",
    "    #learning rate\n",
    "    y_true_lr1, y_pred_lr1 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.1, 'lr1')\n",
    "    y_true_lr2, y_pred_lr2 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'lr2')\n",
    "    y_true_lr3, y_pred_lr3 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 1, 'lr3')\n",
    "\n",
    "    validations = [[y_true_base, y_pred_base],\n",
    "    [y_true_perc1, y_pred_perc1],\n",
    "    [y_true_perc2, y_pred_perc2],\n",
    "    [y_true_perc3, y_pred_perc3],\n",
    "    [y_true_epoch1, y_pred_epoch1],\n",
    "    [y_true_epoch2, y_pred_epoch2],\n",
    "    [y_true_epoch3, y_pred_epoch3],\n",
    "    [y_true_layer1, y_pred_layer1],\n",
    "    [y_true_layer2, y_pred_layer2],\n",
    "    [y_true_layer3, y_pred_layer3],\n",
    "    [y_true_lr1, y_pred_lr1],\n",
    "    [y_true_lr2, y_pred_lr2],\n",
    "    [y_true_lr3, y_pred_lr3]]\n",
    "    \n",
    "    return GenerateScores(validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_linear(X_train, Y_train, X_val, Y_val, X_test, Y_test, C, gamma):   \n",
    "    print(\"svm_linear with C = \"+str(C)+\" and gamma = \"+str(gamma))\n",
    "    clf = SVC(C=C, gamma=gamma, kernel='linear')\n",
    "    clf.fit(X_train, np.ravel(Y_train))\n",
    "    \n",
    "    print(\"Start predictions...\")\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_val = clf.predict(X_val)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, pred_train], [Y_val, pred_val], [Y_test, pred_test]]\n",
    "    a1, f1 = GenerateScores(validations)\n",
    "    print(\"acc = \" + str(a1) + \", f1 = \" + str(f1))\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, C, gamma):   \n",
    "    print(\"svm_rbf with C = \"+str(C)+\" and gamma = \"+str(gamma))\n",
    "    clf = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(X_train, np.ravel(Y_train))\n",
    "    \n",
    "    print(\"Start predictions...\")\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_val = clf.predict(X_val)\n",
    "    pred_test = clf.predict(X_test)\n",
    "    \n",
    "    validations = [[Y_train, pred_train], [Y_val, pred_val], [Y_test, pred_test]]\n",
    "    a1, f1 = GenerateScores(validations)\n",
    "    print(\"acc = \" + str(a1) + \", f1 = \" + str(f1))\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def SVM(x, y):\n",
    "    X_train, X_test = SplitVectorData_NoVal(x, 0.8)\n",
    "    Y_train, Y_test = SplitVectorData_NoVal(y, 0.8)\n",
    "    \n",
    "    Y_pred_lin03= SVM_linear(X_train, Y_train, X_test, 1e-03)\n",
    "    Y_pred_lin01= SVM_linear(X_train, Y_train, X_test, 1e-01)\n",
    "    Y_pred_lin1= SVM_linear(X_train, Y_train, X_test, 1.0)\n",
    "    Y_pred_lin10= SVM_linear(X_train, Y_train, X_test, 10.0)\n",
    "    Y_pred_rbf03_g03= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-03)\n",
    "    Y_pred_rbf01_g03= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-03)\n",
    "    Y_pred_rbf1_g03= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-03)\n",
    "    Y_pred_rbf10_g03= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-03)\n",
    "    Y_pred_rbf03_g01= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-01)\n",
    "    Y_pred_rbf01_g01= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-01)\n",
    "    Y_pred_rbf1_g01= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-01)\n",
    "    Y_pred_rbf10_g01= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-01)\n",
    "    Y_pred_rbf03_g1= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1.0)\n",
    "    Y_pred_rbf01_g1= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1.0)\n",
    "    Y_pred_rbf1_g1= SVM_rbf(X_train, Y_train, X_test, 1.0, 1.0)\n",
    "    Y_pred_rbf10_g1= SVM_rbf(X_train, Y_train, X_test, 10.0, 1.0)\n",
    "    Y_pred_rbf03_g10= SVM_rbf(X_train, Y_train, X_test, 1e-03, 10.0)\n",
    "    Y_pred_rbf01_g10= SVM_rbf(X_train, Y_train, X_test, 1e-01, 10.0)\n",
    "    Y_pred_rbf1_g10= SVM_rbf(X_train, Y_train, X_test, 1.0, 10.0)\n",
    "    Y_pred_rbf10_g10= SVM_rbf(X_train, Y_train, X_test, 10.0, 10.0)\n",
    "    \n",
    "    validations = [[Y_test, Y_pred_lin03],\n",
    "    [Y_test, Y_pred_lin01],\n",
    "    [Y_test, Y_pred_lin1],\n",
    "    [Y_test, Y_pred_lin10],             \n",
    "    [Y_test, Y_pred_rbf03_g03],\n",
    "    [Y_test, Y_pred_rbf01_g03],\n",
    "    [Y_test, Y_pred_rbf1_g03],\n",
    "    [Y_test, Y_pred_rbf10_g03],            \n",
    "    [Y_test, Y_pred_rbf03_g01],\n",
    "    [Y_test, Y_pred_rbf01_g01],\n",
    "    [Y_test, Y_pred_rbf1_g01],\n",
    "    [Y_test, Y_pred_rbf10_g01],              \n",
    "    [Y_test, Y_pred_rbf03_g1],\n",
    "    [Y_test, Y_pred_rbf01_g1],\n",
    "    [Y_test, Y_pred_rbf1_g1],\n",
    "    [Y_test, Y_pred_rbf10_g1],            \n",
    "    [Y_test, Y_pred_rbf03_g10],\n",
    "    [Y_test, Y_pred_rbf01_g10],\n",
    "    [Y_test, Y_pred_rbf1_g10],\n",
    "    [Y_test, Y_pred_rbf10_g10]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAccAndF1ToExcel(name, acc, f1, c_acc, c_f1):\n",
    "    acc_new = pd.DataFrame({'acc': acc})\n",
    "    f1_new = pd.DataFrame({'f1': f1})\n",
    "    wb = load_workbook(name)\n",
    "\n",
    "    ws = wb['Feuil1']\n",
    "\n",
    "    for index, row in acc_new.iterrows():\n",
    "        cell =  c_acc+'%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "        \n",
    "    for index, row in f1_new.iterrows():\n",
    "        cell = c_f1 + '%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "\n",
    "    wb.save(name)\n",
    "\n",
    "\n",
    "    return pd.read_excel(name, index_col=0)\n",
    "\n",
    "#svm = AddAccAndF1ToExcel('svm.xlsx', acc_svm, f1_svm, 'D', 'E')\n",
    "#rn_holdout = AddAccAndF1ToExcel('rn_holdout.xlsx', acc_neurone_holdout, f1_neurone_holdout, 'F', 'G')\n",
    "\n",
    "# For Debugging\n",
    "#print(acc_svm)\n",
    "#print(f1_svm)\n",
    "#print(acc_neurone_holdout)\n",
    "#print(f1_neurone_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ['BIG_BAND', 'BLUES_CONTEMPORARY', 'COUNTRY_TRADITIONAL', 'DANCE', 'ELECTRONICA', 'EXPERIMENTAL',\n",
    "          'FOLK_INTERNATIONAL', 'GOSPEL', 'GRUNGE_EMO', 'HIP_HOP_RAP', 'JAZZ_CLASSIC', 'METAL_ALTERNATIVE', \n",
    "          'METAL_DEATH', 'METAL_HEAVY', 'POP_CONTEMPORARY', 'POP_INDIE', 'POP_LATIN', 'PUNK', 'REGGAE','RNB_SOUL',\n",
    "          'ROCK_ALTERNATIVE', 'ROCK_COLLEGE', 'ROCK_CONTEMPORARY', 'ROCK_HARD', 'ROCK_NEO_PSYCHEDELIA']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Labels)\n",
    "\n",
    "def LabelsStrToInt(array):\n",
    "    return encoder.transform(array)\n",
    "\n",
    "def LabelsIntToStr(array):\n",
    "    return encoder.inverse_transform(array)\n",
    "\n",
    "def GetDataSet(name, nb, length):\n",
    "    fid = open(os.path.normpath('music/tagged_feature_sets/' + name + '/' + name + '.csv'), 'r') \n",
    "\n",
    "    ids = np.zeros((nb, 2), dtype=np.object)\n",
    "    primitives = np.zeros((nb, length), dtype=np.float64)\n",
    "    labels = np.zeros((nb, 1), dtype=np.object)\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "        \n",
    "        ids[count] = element[:2]\n",
    "        primitives[count] = element[2:-1]\n",
    "        labels[count] = element[-1:]\n",
    "\n",
    "        count += 1\n",
    "        if count >= nb:\n",
    "            break\n",
    "\n",
    "    fid.close()\n",
    "    \n",
    "    normalizedPrimitives = NormalizeData(primitives)\n",
    "#     pca = PCA(min())\n",
    "#     normAndReducedDimPrimitves = pca.fit_transform(normalizedPrimitives)\n",
    "    print(len(labels))\n",
    "    return ids, normalizedPrimitives, LabelsStrToInt(labels)\n",
    "\n",
    "# ----- For debug -----\n",
    "#print(count_smooth)\n",
    "#print(count_spiral)\n",
    "#print(count)\n",
    "#print(Galaxies)\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "50000\n",
      "['1' 'TRAAAAK128F9318786']\n",
      "[0.34364904 0.19015385 0.13235502 0.10477413 0.08307906 0.33207739\n",
      " 0.34794747 0.33937687 0.63612821 0.43030456]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "nbData = 50000\n",
    "\n",
    "#-----------Premade with the right length-----------\n",
    "# GetDataSet('msd-mvd_dev', nbData, 420)\n",
    "# GetDataSet('msd-trh_dev', nbData, 420)\n",
    "# GetDataSet('msd-ssd_dev', nbData, 168)\n",
    "# GetDataSet('msd-marsyas_dev_new', nbData, 124)\n",
    "# GetDataSet('msd-jmirderivatives_dev', nbData, 96)\n",
    "# id1, x1, y1 = GetDataSet('msd-rh_dev_new', nbData, 60)\n",
    "# id2, x2, y2 = GetDataSet('msd-jmirmfccs_dev', nbData, 26)\n",
    "# id3, x3, y3 = GetDataSet('msd-jmirlpc_dev', nbData, 20)\n",
    "# GetDataSet('msd-jmirspectral_dev', nbData, 16)\n",
    "# GetDataSet('msd-jmirmoments_dev', nbData, 10)\n",
    "#---------------------------------------------------\n",
    "\n",
    "id1, x1, y1 = GetDataSet('msd-jmirmoments_dev', nbData, 10)\n",
    "id2, x2, y2 = GetDataSet('msd-jmirspectral_dev', nbData, 16)\n",
    "id3, x3, y3 = GetDataSet('msd-jmirlpc_dev', nbData, 20)\n",
    "id4, x4, y4 = GetDataSet('msd-jmirmfccs_dev', nbData, 26)\n",
    "id5, x5, y5 = GetDataSet('msd-rh_dev_new', nbData, 60)\n",
    "id6, x6, y6 = GetDataSet('msd-jmirderivatives_dev', nbData, 96)\n",
    "\n",
    "#----------For Debug-------------\n",
    "print(id1[0])\n",
    "print(x1[0])\n",
    "print(y1[0])\n",
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.132275   0.13422685 0.13042609]\n",
      "[0.09832604 0.09934578 0.09195797]\n",
      "[0.146275   0.13702741 0.13802761]\n",
      "[0.10558446 0.09844179 0.10405672]\n",
      "[0.13045    0.12062412 0.13682737]\n",
      "[0.09391715 0.08773675 0.0985063 ]\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateModelDataFromVector(x1, y1, GaussianNB())\n",
    "a2, f2 = GenerateModelDataFromVector(x2, y2, GaussianNB())\n",
    "a3, f3 = GenerateModelDataFromVector(x3, y3, GaussianNB())\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n",
    "print(a2)\n",
    "print(f2)\n",
    "print(a3)\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07565    0.07361472 0.07161432]\n",
      "[0.07189764 0.07190003 0.070499  ]\n",
      "[0.097525   0.09741948 0.090018  ]\n",
      "[0.08461024 0.09908441 0.08933336]\n",
      "[0.088      0.08221644 0.08541708]\n",
      "[0.08953356 0.10079168 0.10819885]\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateModelDataFromVector(x1, y1, MultinomialNB())\n",
    "a2, f2 = GenerateModelDataFromVector(x2, y2, MultinomialNB())\n",
    "a3, f3 = GenerateModelDataFromVector(x3, y3, MultinomialNB())\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n",
    "print(a2)\n",
    "print(f2)\n",
    "print(a3)\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.643125   0.11642328 0.11382276]\n",
      "[0.64467294 0.11275546 0.11072412]\n",
      "[0.706725   0.11422284 0.11182236]\n",
      "[0.70673831 0.11311131 0.11135751]\n",
      "[0.706875   0.11642328 0.12762553]\n",
      "[0.70755849 0.11322631 0.12447688]\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateModelDataFromVector(x1, y1, CreateDecisionTreeModel(15))\n",
    "a2, f2 = GenerateModelDataFromVector(x2, y2, CreateDecisionTreeModel(15))\n",
    "a3, f3 = GenerateModelDataFromVector(x3, y3, CreateDecisionTreeModel(15))\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n",
    "print(a2)\n",
    "print(f2)\n",
    "print(a3)\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateRandomForestModel():\n",
    "    return RandomForestClassifier(n_estimators=25, max_depth=13, min_samples_split=20, random_state=0, criterion='entropy', n_jobs=3)\n",
    "\n",
    "# a1, f1 = GenerateModelDataFromVector(x1, np.ravel(y1), CreateRandomForestRegModel(14))\n",
    "# a2, f2 = GenerateModelDataFromVector(x2, np.ravel(y2), CreateRandomForestRegModel(14))\n",
    "# a3, f3 = GenerateModelDataFromVector(x3, np.ravel(y3), CreateRandomForestRegModel(14))\n",
    "\n",
    "# print(a1)\n",
    "# print(f1)\n",
    "# print(a2)\n",
    "# print(f2)\n",
    "# print(a3)\n",
    "# print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_val, X1_test = SplitVectorData_Holdout(x1, 0.8)\n",
    "Y1_train, Y1_val, Y1_test = SplitLabels_Holdout(y1, 0.8)\n",
    "\n",
    "X2_train, X2_val, X2_test = SplitVectorData_Holdout(x2, 0.8)\n",
    "Y2_train, Y2_val, Y2_test = SplitLabels_Holdout(y2, 0.8)\n",
    "\n",
    "X3_train, X3_val, X3_test = SplitVectorData_Holdout(x3, 0.8)\n",
    "Y3_train, Y3_val, Y3_test = SplitLabels_Holdout(y3, 0.8)\n",
    "\n",
    "X4_train, X4_val, X4_test = SplitVectorData_Holdout(x4, 0.8)\n",
    "Y4_train, Y4_val, Y4_test = SplitLabels_Holdout(y4, 0.8)\n",
    "\n",
    "X5_train, X5_val, X5_test = SplitVectorData_Holdout(x5, 0.8)\n",
    "Y5_train, Y5_val, Y5_test = SplitLabels_Holdout(y5, 0.8)\n",
    "\n",
    "X6_train, X6_val, X6_test = SplitVectorData_Holdout(x6, 0.8)\n",
    "Y6_train, Y6_val, Y6_test = SplitLabels_Holdout(y6, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_rbf with C = 10.0 and gamma = 10.0\n",
      "Start predictions...\n",
      "acc = [0.364075   0.25025005 0.25485097], f1 = [0.34914461 0.22817566 0.23620963]\n"
     ]
    }
   ],
   "source": [
    "#Y1_pred = SVM_linear(X1_train, Y1_train, X1_val, 1.0, 1e-01)\n",
    "# 1e-03\n",
    "# 1e-01\n",
    "# 1.0\n",
    "# 10.0\n",
    "def svm(X_train, Y_train, X_val, Y_val, X_test, Y_test):\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1e-01, 1e-01)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1.0, 1e-01)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 10.0, 1e-01)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1e-01, 1.0)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1.0, 1.0)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 10.0, 1.0)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1e-01, 10.0)\n",
    "#     a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 1.0, 10.0)\n",
    "    a1, f1 = SVM_rbf(X_train, Y_train, X_val, Y_val, X_test, Y_test, 10.0, 10.0)\n",
    "\n",
    "# svm(X1_train, Y1_train, X1_val, Y1_val, X1_test, Y1_test)\n",
    "# svm(X2_train, Y2_train, X2_val, Y2_val, X2_test, Y2_test)\n",
    "# svm(X3_train, Y3_train, X3_val, Y3_val, X3_test, Y3_test)\n",
    "svm(X4_train, Y4_train, X4_val, Y4_val, X4_test, Y4_test)\n",
    "# svm(X5_train, Y5_train, X5_val, Y5_val, X5_test, Y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCol(array):\n",
    "    a = np.zeros((len(array), 1), dtype=object)\n",
    "    for i in range(0, len(array)-1):\n",
    "        a[i] = array[i]\n",
    "    return a\n",
    "\n",
    "def svm_model():\n",
    "    model = SVC(C=10.0, gamma=10.0, kernel='rbf')\n",
    "    return model\n",
    "\n",
    "def AdaBoost_model():\n",
    "    model = AdaBoostClassifier(base_estimator = CreateDecisionTreeModel(15), n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(X_train, Y_train, X_val, Y_val, layers, perceptrons, epochs, learnRate):\n",
    "    \n",
    "    hiddenLayers = np.zeros((layers,), dtype=int)\n",
    "    for i in range(0, len(hiddenLayers)):\n",
    "        hiddenLayers[i] = perceptrons\n",
    "    \n",
    "    #Create model\n",
    "    model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=hiddenLayers, learning_rate_init=learnRate, \n",
    "                          max_iter=epochs, random_state=1)\n",
    "    \n",
    "    #Train\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Ensemble_model():\n",
    "#     \n",
    "#     model = VotingClassifier(estimators = [ ('DT', CreateRandomForestModel().fit(X2_train, np.ravel(Y2_train))),\n",
    "#                                            ('Ada', AdaBoost_model().fit(X3_train, np.ravel(Y3_train))), \n",
    "#                                            ('SVM', svm_model().fit(X4_train, np.ravel(Y4_train))),\n",
    "#                                            ('CNN', CNN_model(X5_train, Y5_train, X5_val, Y5_val, 3, 120, 60, 0.001))], \n",
    "#                              voting = 'hard', n_jobs=3) \n",
    "#     return model\n",
    "\n",
    "def Ensemble_model():\n",
    "    model = VotingClassifier(estimators = [ ('DT', CreateRandomForestModel()),\n",
    "                                           ('Ada', AdaBoost_model()), \n",
    "                                           ('SVM', svm_model()),\n",
    "                                           ('CNN', MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(120, 120, 120), \n",
    "                                                    learning_rate_init=0.001, max_iter=60, random_state=1))], \n",
    "                                            voting = 'hard', n_jobs=3) \n",
    "    return model\n",
    "\n",
    "# acc = [0.653925   0.65193039 0.65253051], f1 = [0.65487319 0.65407308 0.65322085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = Ensemble_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('DT', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_...\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=3, voting='hard', weights=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.fit(x4, np.ravel(y4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred4_train = ensemble_model.predict(X4_train)\n",
    "pred4_val = ensemble_model.predict(X4_val)\n",
    "pred4_test = ensemble_model.predict(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = [0.653925   0.65193039 0.65253051], f1 = [0.65487319 0.65407308 0.65322085]\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateScores([[Y4_train, pred4_train], [Y4_val, pred4_val], [Y4_test, pred4_test]])\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = [0.1528     0.15443089 0.14682937], f1 = [0.16181572 0.16279614 0.16012514]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_model(X2_train, Y2_train, X2_val, Y2_val, 3, 120, 60, 0.001)\n",
    "\n",
    "Y_train_pred = cnn.predict(X2_train)   \n",
    "Y_val_pred = cnn.predict(X2_val)   \n",
    "Y_test_pred = cnn.predict(X2_test)   \n",
    "\n",
    "a1, f1 = GenerateScores([[Y2_train, Y_train_pred], [Y2_val, Y_val_pred], [Y2_test, Y_test_pred]])\n",
    "print(\"acc = \" + str(a1) + \", f1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VoteClassifier(x, y, X_train, Y_train, X_val, Y_val, Y_test, X_test, name):\n",
    "    ensemble_model = Ensemble_model()\n",
    "\n",
    "    ensemble_model.fit(x, np.ravel(y))\n",
    "\n",
    "    pred_train = ensemble_model.predict(X_train)\n",
    "    pred_val = ensemble_model.predict(X_val)\n",
    "    pred_test = ensemble_model.predict(X_test)\n",
    "\n",
    "    a1, f1 = GenerateScores([[Y_train, pred_train], [Y_val, pred_val], [Y_test, pred_test]])\n",
    "    print(\"Results for set \" + name + \" : \")\n",
    "    print(\"acc = \" + str(a1) + \", f1 = \" + str(f1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 1 with 10 feature : \n",
      "acc = [0.45775    0.46189238 0.44428886], f1 = [0.44789647 0.45390956 0.43319022]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 2 with 16 feature : \n",
      "acc = [0.53665    0.54230846 0.5425085 ], f1 = [0.53403494 0.5402461  0.5380138 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 3 with 20 feature : \n",
      "acc = [0.594475   0.59531906 0.58891778], f1 = [0.59298286 0.59467295 0.58792654]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 4 with 26 feature : \n",
      "acc = [0.653925   0.65193039 0.65253051], f1 = [0.65487319 0.65407308 0.65322085]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 5 with 60 feature : \n",
      "acc = [0.801425   0.80636127 0.78955791], f1 = [0.80643288 0.81097645 0.79502129]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "VoteClassifier(x1, y1, X1_train, Y1_train, X1_val, Y1_val, Y1_test, X1_test, \"1 with 10 feature\")\n",
    "VoteClassifier(x2, y2, X2_train, Y2_train, X2_val, Y2_val, Y2_test, X2_test, \"2 with 16 feature\")\n",
    "VoteClassifier(x3, y3, X3_train, Y3_train, X3_val, Y3_val, Y3_test, X3_test, \"3 with 20 feature\")\n",
    "VoteClassifier(x4, y4, X4_train, Y4_train, X4_val, Y4_val, Y4_test, X4_test, \"4 with 26 feature\")\n",
    "VoteClassifier(x5, y5, X5_train, Y5_train, X5_val, Y5_val, Y5_test, X5_test, \"5 with 60 feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for set 6 with 96 feature : \n",
      "acc = [0.7974     0.80656131 0.79615923], f1 = [0.79905731 0.80818421 0.79849798]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "VoteClassifier(x6, y6, X6_train, Y6_train, X6_val, Y6_val, Y6_test, X6_test, \"6 with 96 feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(convertToCol(Y1_pred)[0])\n",
    "# print(Y1_val[2])\n",
    "# validations = [[Y1_test, Y1_pred]]\n",
    "# a1, f1 = GenerateScores(validations)\n",
    "\n",
    "\n",
    "\n",
    "# print(a1)\n",
    "# print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galaxies_norm = NormalizeData(Galaxies)\n",
    "#acc_neurone_holdout, f1_neurone_holdout = Neurone_Holdout(Galaxies)\n",
    "\n",
    "#acc_neurone_holdout\n",
    "\n",
    "#acc_svm, f1_svm = SVM(Galaxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
