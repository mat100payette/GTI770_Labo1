{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GTI770 - TP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import graphviz\n",
    "import decimal\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers as opt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mdlp.discretization import MDLP\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility methods\n",
    "def SplitVectorData_Holdout(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    val_portion = (1 - train_portion) / 2\n",
    "    test_portion = (1 - train_portion) / 2\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbVal = int(size * val_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_val = np.zeros((nbVal, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_val = primitives_vector[nbTrain : nbTrain + nbVal]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_val, array_test\n",
    "\n",
    "def SplitVectorData_KFold(primitives_vector, k, test_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    subsetNb = int(size * (1 - test_portion) / k)\n",
    "    testNb = int(size * test_portion)\n",
    "    \n",
    "    array_kfold_train = np.zeros((k, subsetNb, subsize), dtype=np.float64)\n",
    "    array_kfold_test = np.zeros((testNb, subsize), dtype=np.float64)\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        if i == 0 :\n",
    "            array_kfold_train[i] = primitives_vector[i * subsetNb]\n",
    "        else :\n",
    "            array_kfold_train[i] = primitives_vector[(i-1) * subsetNb : i * subsetNb]\n",
    "    \n",
    "    array_kfold_test = primitives_vector[-testNb:]\n",
    "\n",
    "    return array_kfold_train, array_kfold_test\n",
    "\n",
    "def SplitVectorData_NoVal(primitives_vector, train_portion):\n",
    "    \n",
    "    size = len(primitives_vector)\n",
    "    subsize = len(primitives_vector[0])\n",
    "    \n",
    "    test_portion = (1 - train_portion)\n",
    "\n",
    "    nbTrain = int(size * train_portion)\n",
    "    nbTest = int(size * test_portion)\n",
    "\n",
    "    array_train = np.zeros((nbTrain, subsize), dtype=np.float64)\n",
    "    array_test = np.zeros((nbTest, subsize), dtype=np.float64)\n",
    "\n",
    "    array_train = primitives_vector[:nbTrain]\n",
    "    array_test = primitives_vector[-nbTest:]\n",
    "    return array_train, array_test\n",
    "\n",
    "def concatenateWithoutTestPortion(full_array, index):\n",
    "    result_array = []\n",
    "    for i in range(0, len(full_array)):\n",
    "        if len(result_array) == 0:\n",
    "            result_array = full_array[i]\n",
    "        elif i != index :\n",
    "            result_array = np.concatenate((result_array, full_array[i]), axis=0)\n",
    "    return result_array\n",
    "\n",
    "def scores_mean(array_scores):\n",
    "    \n",
    "    size = len(array_scores)\n",
    "    subsize = len(array_scores[0])\n",
    "    array_mean = np.zeros(subsize, dtype=float)\n",
    "    \n",
    "    for i in range(0, size):\n",
    "        for j in range(0, subsize):\n",
    "            array_mean[j] += array_scores[i][j]\n",
    "            \n",
    "    for j in range(0, subsize):\n",
    "            array_mean[j] = array_mean[j] / size\n",
    "    \n",
    "    return array_mean\n",
    "\n",
    "def UseModelOnTestData(array, model, transformer=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if transformer is not None:\n",
    "        transform_train, transform_val, transform_test, Y_train, Y_val, Y_test = TransformData(array_train, array_val, array_test, len(array_train[0]), transformer)\n",
    "    array_model_result, array_prediction_train_result, array_prediction_val_result, array_prediction_test_result, array_train_result, array_val_result, array_test_result = GenerateModelDataFromTransform(transform_train, transform_val, transform_test, Y_train, Y_val, Y_test, len(array[0]), model)\n",
    "    result = [[array_test_result, array_prediction_test_result]]\n",
    "    return GenerateScores(result) \n",
    "\n",
    "# ----- For debug -----\n",
    "#Filter_train, Filter_val, Filter_test = SplitVectorDataTrainValTest(Filter, 0.6)\n",
    "#print(len(Filter_train))\n",
    "#print(len(Filter_val))\n",
    "#print(len(Filter_test))\n",
    "#print(len(Filter))\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms and Models generation methods\n",
    "\n",
    "def GenerateModelDataFromVector(x, y, chosen_model):\n",
    "    \n",
    "    X_train, X_val, X_test = SplitVectorData_Holdout(x, 0.8)\n",
    "    Y_train, Y_val, Y_test = SplitVectorData_Holdout(y, 0.8)\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    \n",
    "    validations = [[prediction_train, Y_train], [prediction_val, Y_val], [prediction_test, Y_test]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def TransformData(array_train, array_val, array_test, num_features, chosen_transformer):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    data_train = array_train\n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "    \n",
    "    data_val = array_val\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "    \n",
    "    data_test = array_test\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    \n",
    "    transformer_train = chosen_transformer\n",
    "    transformer_train = transformer_train.fit_transform(X_train, Y_train)\n",
    "    \n",
    "    transformer_val = chosen_transformer\n",
    "    transformer_val = transformer_val.fit_transform(X_val, Y_val)\n",
    "    \n",
    "    transformer_test = chosen_transformer\n",
    "    transformer_test = transformer_test.fit_transform(X_test, Y_test)\n",
    "    return transformer_train, transformer_val, transformer_test, Y_train, Y_val, Y_test\n",
    "\n",
    "def GenerateModelDataFromTransform(array_train, array_val, array_test, y_train, y_val, y_test, num_features, chosen_model):\n",
    "    \n",
    "    num_features = num_features - 1\n",
    "    \n",
    "    X_train  = array_train\n",
    "    Y_train = y_train\n",
    "    \n",
    "    X_val = array_val\n",
    "    Y_val = y_val\n",
    "    \n",
    "    X_test  = array_test\n",
    "    Y_test = y_test\n",
    "    \n",
    "    model = chosen_model\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    prediction_train = model.predict(X_train)\n",
    "    prediction_val = model.predict(X_val)\n",
    "    prediction_test = model.predict(X_test)\n",
    "    return model, prediction_train, prediction_val, prediction_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display methods\n",
    "def ExportTree(model):\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                         #feature_names = ['', '', ''],  \n",
    "                         class_names = ['spam', 'mail'],\n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render(\"Filter_data\") \n",
    "    return graph\n",
    "\n",
    "def GenerateScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "    F1Scores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "        F1Scores[i] = f1_score(array[i][0], array[i][1], average='weighted', labels=np.unique(array[i][1]))\n",
    "    \n",
    "    return AccScores, F1Scores\n",
    "\n",
    "def GenerateAccScores(array):\n",
    "    AccScores = np.zeros(len(array), dtype=float)\n",
    "\n",
    "    for i in range(0, len(array)):\n",
    "        AccScores[i] = accuracy_score(array[i][0], array[i][1])\n",
    "    \n",
    "    return AccScores\n",
    "\n",
    "#Extraction de primitive\n",
    "def TracePlot(array_acc_X, array_acc_Y, array_f1_X, array_f1_Y, titre, titre_x, titre_y):        \n",
    "    \n",
    "    plt.plot(array_acc_X, array_acc_Y, 'ro')\n",
    "    plt.plot(array_f1_X, array_f1_Y, 'g*')\n",
    "    plt.xlabel(titre_x)\n",
    "    plt.ylabel(titre_y)\n",
    "    plt.legend(['Accuracy Score','F1 Score'])\n",
    "    plt.title(titre)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model creations methods\n",
    "def CreateDecisionTreeModel(depth):\n",
    "    return tree.DecisionTreeClassifier(criterion='entropy', max_depth=depth, min_samples_leaf=1)\n",
    "\n",
    "def CreateKNNModel(k, weight):\n",
    "    return KNeighborsClassifier(n_neighbors=k, weights=weight)\n",
    "\n",
    "def CreateRandomForestModel(depth):\n",
    "    return RandomForestClassifier(criterion='entropy', max_depth=depth, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree methods\n",
    "def DecisionTree_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def DecisionTree_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateDecisionTreeModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bayes Methods\n",
    "def Bayes_Holdout(array, array_prob ,array_transform=None):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    if array_transform is not None:\n",
    "        array_train_tr, array_val_tr, array_test_tr = SplitVectorData_Holdout(array_transform, 0.6)\n",
    "\n",
    "    transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "    transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "    if array_transform is not None:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "    else:\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "\n",
    "    array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "    array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "    validations = [[array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10],\n",
    "    [array_val_mdlp, array_prediction_val_mdlp],\n",
    "    [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "    return GenerateScores(validations)  \n",
    "    \n",
    "def Bayes_KFold(array, array_prob, k, array_transform=None):\n",
    "    \n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    if array_transform is not None:\n",
    "        array_kfold_train_tr, array_kfold_test_tr = SplitVectorData_KFold(array_transform, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "        \n",
    "        if array_transform is not None:\n",
    "            array_train_tr = concatenateWithoutTestPortion(array_kfold_train_tr, i)\n",
    "            array_val_tr = array_kfold_train_tr[i]\n",
    "            array_test_tr = array_kfold_test_tr\n",
    "\n",
    "        transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp = TransformData(array_train, array_val, array_test, len(array_train[0]), MDLP())\n",
    "        transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax = TransformData(array_train, array_val, array_test, len(array_train[0]), MinMaxScaler())\n",
    "\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), GaussianNB(priors=array_prob))\n",
    "        if array_transform is not None:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train_tr, array_val_tr, array_test_tr, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        else:\n",
    "            array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), MultinomialNB(fit_prior=True, class_prior=array_prob))\n",
    "        array_model_mdlp, array_prediction_train_mdlp, array_prediction_val_mdlp, array_prediction_test_mdlp, array_train_mdlp, array_val_mdlp, array_test_mdlp = GenerateModelDataFromTransform(transform_train_mdlp, transform_val_mdlp, transform_test_mdlp, Y_train_mdlp, Y_val_mdlp, Y_test_mdlp, len(array[0]), MultinomialNB())\n",
    "        array_model_minmax, array_prediction_train_minmax, array_prediction_val_minmax, array_prediction_test_minmax, array_train_minmax, array_val_minmax, array_test_minmax = GenerateModelDataFromTransform(transform_train_minmax, transform_val_minmax, transform_test_minmax, Y_train_minmax, Y_val_minmax, Y_test_minmax, len(array[0]), MultinomialNB())\n",
    "\n",
    "\n",
    "        validations = [[array_val_5, array_prediction_val_5],\n",
    "                     [array_val_10, array_prediction_val_10],\n",
    "                     [array_val_mdlp, array_prediction_val_mdlp],\n",
    "                     [array_val_minmax, array_prediction_val_minmax]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores \n",
    "        \n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "\n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Methods\n",
    "def KNN_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "    array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "    array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "    array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "    array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "    array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "    validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "                        [array_val_5u, array_prediction_val_5u],\n",
    "                        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "    validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "                        [array_val_5d, array_prediction_val_5d],\n",
    "                        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "    accScores_uniform, f1Scores_uniform = GenerateScores(validations_uniform)\n",
    "    accScores_distance, f1Scores_dsitance = GenerateScores(validations_distance)\n",
    "\n",
    "    return accScores_uniform, f1Scores_uniform, accScores_distance, f1Scores_dsitance\n",
    "    \n",
    "def KNN_KFold(array, k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_uniform = np.zeros((k, 3), dtype=float)\n",
    "    all_accScores_distance = np.zeros((k, 3), dtype=float)\n",
    "    all_f1Scores_distance = np.zeros((k, 3), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_3u, array_prediction_train_3u, array_prediction_val_3u, array_prediction_test_3u, array_train_3u, array_val_3u, array_test_3u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'uniform'))\n",
    "        array_model_5u, array_prediction_train_5u, array_prediction_val_5u, array_prediction_test_5u, array_train_5u, array_val_5u, array_test_5u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'uniform'))\n",
    "        array_model_10u, array_prediction_train_10u, array_prediction_val_10u, array_prediction_test_10u, array_train_10u, array_val_10u, array_test_10u = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'uniform'))\n",
    "        array_model_3d, array_prediction_train_3d, array_prediction_val_3d, array_prediction_test_3d, array_train_3d, array_val_3d, array_test_3d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(3, 'distance'))\n",
    "        array_model_5d, array_prediction_train_5d, array_prediction_val_5d, array_prediction_test_5d, array_train_5d, array_val_5d, array_test_5d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(5, 'distance'))\n",
    "        array_model_10d, array_prediction_train_10d, array_prediction_val_10d, array_prediction_test_10d, array_train_10d, array_val_10d, array_test_10d = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateKNNModel(10, 'distance'))\n",
    "\n",
    "        validations_uniform = [[array_val_3u, array_prediction_val_3u],\n",
    "        [array_val_5u, array_prediction_val_5u],\n",
    "        [array_val_10u, array_prediction_val_10u]]\n",
    "\n",
    "        validations_distance = [[array_val_3d, array_prediction_val_3d],\n",
    "        [array_val_5d, array_prediction_val_5d],\n",
    "        [array_val_10d, array_prediction_val_10d]]\n",
    "\n",
    "        Array_AccScores_uniform, Array_F1Scores_uniform = GenerateScores(validations_uniform)\n",
    "        Array_AccScores_distance, Array_F1Scores_distance = GenerateScores(validations_distance)\n",
    "\n",
    "        all_accScores_uniform[i] = Array_AccScores_uniform\n",
    "        all_f1Scores_uniform[i] = Array_F1Scores_uniform\n",
    "        all_accScores_distance[i] = Array_AccScores_distance\n",
    "        all_f1Scores_distance[i] = Array_F1Scores_distance\n",
    "\n",
    "    accScores_mean_uniform = scores_mean(all_accScores_uniform)\n",
    "    f1Scores_mean_uniform = scores_mean(all_f1Scores_uniform)\n",
    "    accScores_mean_distance = scores_mean(all_accScores_distance)\n",
    "    f1Scores_mean_distance = scores_mean(all_f1Scores_distance)\n",
    "\n",
    "    return accScores_mean_uniform, f1Scores_mean_uniform, accScores_mean_distance, f1Scores_mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest methods\n",
    "def RandomForest_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "\n",
    "    array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "    array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "    array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "    array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "    validations = [[array_val_none, array_prediction_val_none],\n",
    "    [array_val_3, array_prediction_val_3],\n",
    "    [array_val_5, array_prediction_val_5],\n",
    "    [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "    return GenerateScores(validations)\n",
    "\n",
    "def RandomForest_KFold(array,k):\n",
    "\n",
    "    array_kfold_train, array_kfold_test = SplitVectorData_KFold(array, k, 0.2)\n",
    "    all_accScores = np.zeros((k, 4), dtype=float)\n",
    "    all_f1Scores = np.zeros((k, 4), dtype=float)\n",
    "\n",
    "    for i in range(1, k):\n",
    "\n",
    "        array_train = concatenateWithoutTestPortion(array_kfold_train, i)\n",
    "        array_val = array_kfold_train[i]\n",
    "        array_test = array_kfold_test\n",
    "\n",
    "        array_model_none, array_prediction_train_none, array_prediction_val_none, array_prediction_test_none, array_train_none, array_val_none, array_test_none = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(None))\n",
    "        array_model_3, array_prediction_train_3, array_prediction_val_3, array_prediction_test_3, array_train_3, array_val_3, array_test_3 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(3))\n",
    "        array_model_5, array_prediction_train_5, array_prediction_val_5, array_prediction_test_tree_5, array_train_5, array_val_5, array_test_5 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(5))\n",
    "        array_model_10, array_prediction_train_10, array_prediction_val_10, array_prediction_test_tree_10, array_train_10, array_val_10, array_test_10 = GenerateModelDataFromVector(array_train, array_val, array_test, len(array[0]), CreateRandomForestModel(10))\n",
    "\n",
    "        validations = [[array_val_none, array_prediction_val_none],\n",
    "        [array_val_3, array_prediction_val_3],\n",
    "        [array_val_5, array_prediction_val_5],\n",
    "        [array_val_10, array_prediction_val_10]]\n",
    "\n",
    "        Array_AccScores, Array_F1Scores = GenerateScores(validations)\n",
    "\n",
    "        all_accScores[i] = Array_AccScores\n",
    "        all_f1Scores[i] = Array_F1Scores\n",
    "\n",
    "    accScores_mean = scores_mean(all_accScores)\n",
    "    f1Scores_mean = scores_mean(all_f1Scores)\n",
    "    \n",
    "    return accScores_mean, f1Scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return normalize(data, norm='l2')\n",
    "\n",
    "def GetGalaxiesClassProbabilities():\n",
    "    count_smooth = 0\n",
    "    count_spiral = 0\n",
    "    \n",
    "    fid = open('galaxy_feature_vectors.csv', 'r') \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "\n",
    "        label = float(element[75])\n",
    "\n",
    "        if label == 0.0:\n",
    "            count_smooth += 1     \n",
    "        elif label == 1.0:\n",
    "            count_spiral += 1\n",
    "    return [count_smooth/(count_smooth+count_spiral), count_spiral/(count_smooth+count_spiral)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SplitLabelsFromPrimitives(data_train, data_val, data_test):\n",
    "    num_features = len(data_train[0]) - 1\n",
    "    \n",
    "    X_train  = data_train[:,0:num_features]\n",
    "    Y_train  = data_train[:,num_features]\n",
    "\n",
    "    X_val  = data_val[:,0:num_features]\n",
    "    Y_val  = data_val[:,num_features]\n",
    "\n",
    "    X_test  = data_test[:,0:num_features]\n",
    "    Y_test  = data_test[:,num_features]\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "\n",
    "def GenerateModel(data_train, data_val, data_test, layers, perceptrons, epochs, learnRate, name):\n",
    "    \n",
    "    #Split labels from the primitives\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = SplitLabelsFromPrimitives(data_train, data_val, data_test)\n",
    "    \n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    #Add layers\n",
    "    model.add(Dense(units=perceptrons, activation='sigmoid', input_shape=(len(X_train[0]),)))\n",
    "    model.add(Dropout(0.2))\n",
    "    for i in range(0, layers - 2):\n",
    "        model.add(Dense(units=perceptrons, activation='sigmoid'))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=2, activation='sigmoid'))\n",
    "    \n",
    "    #Set optimizers and compile\n",
    "    sgd = opt.SGD(lr=learnRate, decay=0, momentum=0, nesterov=False)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    #Use TensorBoard\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs/'+name)\n",
    "    \n",
    "    #Train\n",
    "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=100, callbacks=[tb_callback])\n",
    "    \n",
    "    model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    Y_probs = model.predict(X_test)\n",
    "    \n",
    "    Y_pred = Y_probs.argmax(axis=1)\n",
    "    \n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_pred)\n",
    "    #plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test)\n",
    "\n",
    "    return Y_test, Y_pred\n",
    "\n",
    "def Neurone_Holdout(array):\n",
    "    array_train, array_val, array_test = SplitVectorData_Holdout(array, 0.6)\n",
    "    \n",
    "    AccScores = np.zeros(13, dtype=float)\n",
    "    \n",
    "    #base\n",
    "    y_true_base, y_pred_base = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'base')\n",
    "    \n",
    "    #perceptrons\n",
    "    y_true_perc1, y_pred_perc1 = GenerateModel(array_train, array_val, array_test, 4, 50, 60, 0.5, 'perc1')\n",
    "    y_true_perc2, y_pred_perc2 = GenerateModel(array_train, array_val, array_test, 4, 300, 60, 0.5, 'perc2')\n",
    "    y_true_perc3, y_pred_perc3 = GenerateModel(array_train, array_val, array_test, 4, 600, 60, 0.5, 'perc3')\n",
    "\n",
    "    #epochs\n",
    "    y_true_epoch1, y_pred_epoch1 = GenerateModel(array_train, array_val, array_test, 4, 100, 30, 0.5, 'epoch1')\n",
    "    y_true_epoch2, y_pred_epoch2 = GenerateModel(array_train, array_val, array_test, 4, 100, 120, 0.5, 'epoch2')\n",
    "    y_true_epoch3, y_pred_epoch3 = GenerateModel(array_train, array_val, array_test, 4, 100, 240, 0.5, 'epoch3')\n",
    "    \n",
    "    #layers\n",
    "    y_true_layer1, y_pred_layer1 = GenerateModel(array_train, array_val, array_test, 6, 100, 60, 0.5, 'layer1')\n",
    "    y_true_layer2, y_pred_layer2 = GenerateModel(array_train, array_val, array_test, 12, 100, 60, 0.5, 'layer2')\n",
    "    y_true_layer3, y_pred_layer3 = GenerateModel(array_train, array_val, array_test, 24, 100, 60, 0.5, 'layer3')\n",
    "    \n",
    "    #learning rate\n",
    "    y_true_lr1, y_pred_lr1 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.1, 'lr1')\n",
    "    y_true_lr2, y_pred_lr2 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 0.5, 'lr2')\n",
    "    y_true_lr3, y_pred_lr3 = GenerateModel(array_train, array_val, array_test, 4, 100, 60, 1, 'lr3')\n",
    "\n",
    "    validations = [[y_true_base, y_pred_base],\n",
    "    [y_true_perc1, y_pred_perc1],\n",
    "    [y_true_perc2, y_pred_perc2],\n",
    "    [y_true_perc3, y_pred_perc3],\n",
    "    [y_true_epoch1, y_pred_epoch1],\n",
    "    [y_true_epoch2, y_pred_epoch2],\n",
    "    [y_true_epoch3, y_pred_epoch3],\n",
    "    [y_true_layer1, y_pred_layer1],\n",
    "    [y_true_layer2, y_pred_layer2],\n",
    "    [y_true_layer3, y_pred_layer3],\n",
    "    [y_true_lr1, y_pred_lr1],\n",
    "    [y_true_lr2, y_pred_lr2],\n",
    "    [y_true_lr3, y_pred_lr3]]\n",
    "    \n",
    "    return GenerateScores(validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_linear(X_train, Y_train, X_test):\n",
    "    C_range = np.logspace(-3, 3, 7)\n",
    "    gamma_range = np.logspace(-5, 3, 9)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    grid = GridSearchCV(SVC(cache_size=2048), param_grid=param_grid, cv=cv, n_jobs=7)\n",
    "    grid.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "    clf = SVC(C=grid.best_params_['C'], gamma=grid.best_params_['gamma'], class_weight='balanced', kernel='linear')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def SVM_rbf(X_train, Y_train, X_test, C, gamma):\n",
    "\n",
    "    clf = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return Y_pred\n",
    "\n",
    "def SVM(x, y):\n",
    "    X_train, X_test = SplitVectorData_NoVal(x, 0.8)\n",
    "    Y_train, Y_test = SplitVectorData_NoVal(y, 0.8)\n",
    "    \n",
    "    Y_pred_lin03= SVM_linear(X_train, Y_train, X_test, 1e-03)\n",
    "    Y_pred_lin01= SVM_linear(X_train, Y_train, X_test, 1e-01)\n",
    "    Y_pred_lin1= SVM_linear(X_train, Y_train, X_test, 1.0)\n",
    "    Y_pred_lin10= SVM_linear(X_train, Y_train, X_test, 10.0)\n",
    "    Y_pred_rbf03_g03= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-03)\n",
    "    Y_pred_rbf01_g03= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-03)\n",
    "    Y_pred_rbf1_g03= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-03)\n",
    "    Y_pred_rbf10_g03= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-03)\n",
    "    Y_pred_rbf03_g01= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1e-01)\n",
    "    Y_pred_rbf01_g01= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1e-01)\n",
    "    Y_pred_rbf1_g01= SVM_rbf(X_train, Y_train, X_test, 1.0, 1e-01)\n",
    "    Y_pred_rbf10_g01= SVM_rbf(X_train, Y_train, X_test, 10.0, 1e-01)\n",
    "    Y_pred_rbf03_g1= SVM_rbf(X_train, Y_train, X_test, 1e-03, 1.0)\n",
    "    Y_pred_rbf01_g1= SVM_rbf(X_train, Y_train, X_test, 1e-01, 1.0)\n",
    "    Y_pred_rbf1_g1= SVM_rbf(X_train, Y_train, X_test, 1.0, 1.0)\n",
    "    Y_pred_rbf10_g1= SVM_rbf(X_train, Y_train, X_test, 10.0, 1.0)\n",
    "    Y_pred_rbf03_g10= SVM_rbf(X_train, Y_train, X_test, 1e-03, 10.0)\n",
    "    Y_pred_rbf01_g10= SVM_rbf(X_train, Y_train, X_test, 1e-01, 10.0)\n",
    "    Y_pred_rbf1_g10= SVM_rbf(X_train, Y_train, X_test, 1.0, 10.0)\n",
    "    Y_pred_rbf10_g10= SVM_rbf(X_train, Y_train, X_test, 10.0, 10.0)\n",
    "    \n",
    "    validations = [[Y_test, Y_pred_lin03],\n",
    "    [Y_test, Y_pred_lin01],\n",
    "    [Y_test, Y_pred_lin1],\n",
    "    [Y_test, Y_pred_lin10],             \n",
    "    [Y_test, Y_pred_rbf03_g03],\n",
    "    [Y_test, Y_pred_rbf01_g03],\n",
    "    [Y_test, Y_pred_rbf1_g03],\n",
    "    [Y_test, Y_pred_rbf10_g03],            \n",
    "    [Y_test, Y_pred_rbf03_g01],\n",
    "    [Y_test, Y_pred_rbf01_g01],\n",
    "    [Y_test, Y_pred_rbf1_g01],\n",
    "    [Y_test, Y_pred_rbf10_g01],              \n",
    "    [Y_test, Y_pred_rbf03_g1],\n",
    "    [Y_test, Y_pred_rbf01_g1],\n",
    "    [Y_test, Y_pred_rbf1_g1],\n",
    "    [Y_test, Y_pred_rbf10_g1],            \n",
    "    [Y_test, Y_pred_rbf03_g10],\n",
    "    [Y_test, Y_pred_rbf01_g10],\n",
    "    [Y_test, Y_pred_rbf1_g10],\n",
    "    [Y_test, Y_pred_rbf10_g10]]\n",
    "    \n",
    "    return GenerateScores(validations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAccAndF1ToExcel(name, acc, f1, c_acc, c_f1):\n",
    "    acc_new = pd.DataFrame({'acc': acc})\n",
    "    f1_new = pd.DataFrame({'f1': f1})\n",
    "    wb = load_workbook(name)\n",
    "\n",
    "    ws = wb['Feuil1']\n",
    "\n",
    "    for index, row in acc_new.iterrows():\n",
    "        cell =  c_acc+'%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "        \n",
    "    for index, row in f1_new.iterrows():\n",
    "        cell = c_f1 + '%d'  % (index + 2)\n",
    "        ws[cell] = row[0]\n",
    "\n",
    "    wb.save(name)\n",
    "\n",
    "\n",
    "    return pd.read_excel(name, index_col=0)\n",
    "\n",
    "#svm = AddAccAndF1ToExcel('svm.xlsx', acc_svm, f1_svm, 'D', 'E')\n",
    "#rn_holdout = AddAccAndF1ToExcel('rn_holdout.xlsx', acc_neurone_holdout, f1_neurone_holdout, 'F', 'G')\n",
    "\n",
    "# For Debugging\n",
    "#print(acc_svm)\n",
    "#print(f1_svm)\n",
    "#print(acc_neurone_holdout)\n",
    "#print(f1_neurone_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ['BIG_BAND', 'BLUES_CONTEMPORARY', 'COUNTRY_TRADITIONAL', 'DANCE,ELECTRONICA', 'EXPERIMENTAL',\n",
    "          'FOLK_INTERNATIONAL', 'GOSPEL', 'GRUNGE_EMO', 'HIP_HOP_RAP', 'JAZZ_CLASSIC', 'METAL_ALTERNATIVE', \n",
    "          'METAL_DEATH', 'METAL_HEAVY', 'POP_CONTEMPORARY', 'POP_INDIE', 'POP_LATIN', 'PUNK', 'REGGAE','RNB_SOUL',\n",
    "          'ROCK_ALTERNATIVE', 'ROCK_COLLEGE', 'ROCK_CONTEMPORARY', 'ROCK_HARD', 'ROCK_NEO_PSYCHEDELIA']\n",
    "\n",
    "def GetDataSet(name, nb, length):\n",
    "    fid = open(os.path.normpath('music/tagged_feature_sets/' + name + '/' + name + '.csv'), 'r') \n",
    "\n",
    "    ids = np.zeros((nb, 2), dtype=np.object)\n",
    "    primitives = np.zeros((nb, length), dtype=np.float64)\n",
    "    labels = np.zeros((nb, 1), dtype=np.object)\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for line in fid:\n",
    "        element = line.rstrip('\\n').split(',')\n",
    "        \n",
    "        ids[count] = element[:2]\n",
    "        primitives[count] = element[2:-1]\n",
    "        labels[count] = element[-1:]\n",
    "\n",
    "        count += 1\n",
    "        if count >= nb:\n",
    "            break\n",
    "\n",
    "    fid.close()\n",
    "    \n",
    "    normalizedPrimitives = NormalizeData(primitives)\n",
    "#     pca = PCA(min())\n",
    "#     normAndReducedDimPrimitves = pca.fit_transform(normalizedPrimitives)\n",
    "    \n",
    "    return ids, normalizedPrimitives, labels\n",
    "\n",
    "# ----- For debug -----\n",
    "#print(count_smooth)\n",
    "#print(count_spiral)\n",
    "#print(count)\n",
    "#print(Galaxies)\n",
    "#----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "60\n",
      "1\n",
      "['1' 'TRAAAAK128F9318786']\n",
      "[0.37573443 0.30204786 0.30213912 0.23003151 0.21258275 0.17831855\n",
      " 0.1617979  0.13575716 0.1346128  0.19720725 0.14822409 0.16374234\n",
      " 0.14573671 0.12899064 0.16454648 0.11999906 0.11672645 0.10408622\n",
      " 0.11170205 0.18175469 0.09662782 0.10481348 0.08499637 0.09945083\n",
      " 0.11707531 0.08639207 0.10268426 0.101053   0.08925051 0.08773466\n",
      " 0.07860667 0.08256497 0.07324179 0.08683791 0.07987565 0.0718705\n",
      " 0.06287233 0.06440923 0.08931775 0.12376471 0.07137427 0.07082021\n",
      " 0.06508738 0.06520548 0.06601167 0.06519469 0.06526181 0.05927705\n",
      " 0.05947832 0.06915396 0.06321889 0.06650767 0.06175206 0.08062828\n",
      " 0.06112259 0.05578227 0.06208365 0.05513733 0.05881701 0.05973913]\n",
      "['METAL_ALTERNATIVE']\n"
     ]
    }
   ],
   "source": [
    "nbData = 50000\n",
    "\n",
    "#-----------Premade with the right length-----------\n",
    "# GetDataSet('msd-mvd_dev', nbData, 420)\n",
    "# GetDataSet('msd-trh_dev', nbData, 420)\n",
    "# GetDataSet('msd-ssd_dev', nbData, 168)\n",
    "# GetDataSet('msd-marsyas_dev_new', nbData, 124)\n",
    "# GetDataSet('msd-jmirderivatives_dev', nbData, 96)\n",
    "id1, x1, y1 = GetDataSet('msd-rh_dev_new', nbData, 60)\n",
    "id2, x2, y2 = GetDataSet('msd-jmirmfccs_dev', nbData, 26)\n",
    "id3, x3, y3 = GetDataSet('msd-jmirlpc_dev', nbData, 20)\n",
    "# GetDataSet('msd-jmirspectral_dev', nbData, 16)\n",
    "# GetDataSet('msd-jmirmoments_dev', nbData, 10)\n",
    "#---------------------------------------------------\n",
    "\n",
    "# id1, x1, y1 = GetDataSet('msd-jmirmoments_dev', nbData, 10)\n",
    "# id2, x2, y2 = GetDataSet('msd-jmirspectral_dev', nbData, 16)\n",
    "# id3, x3, y3 = GetDataSet('msd-jmirlpc_dev', nbData, 20)\n",
    "\n",
    "#----------For Debug-------------\n",
    "print(len(id1[0]))\n",
    "print(len(x1[0]))\n",
    "print(len(y1[0]))\n",
    "\n",
    "print(id1[0])\n",
    "print(x1[0])\n",
    "print(y1[0])\n",
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.124775   0.11162232 0.12602521]\n",
      "[0.14035337 0.1275442  0.14312204]\n",
      "[0.166775   0.16663333 0.16423285]\n",
      "[0.19475283 0.19545222 0.18973341]\n",
      "[0.1386     0.12762553 0.14222845]\n",
      "[0.17585719 0.16633298 0.18107755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateModelDataFromVector(x1, y1, GaussianNB())\n",
    "a2, f2 = GenerateModelDataFromVector(x2, y2, GaussianNB())\n",
    "a3, f3 = GenerateModelDataFromVector(x3, y3, GaussianNB())\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n",
    "print(a2)\n",
    "print(f2)\n",
    "print(a3)\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1851     0.11942388 0.13102621]\n",
      "[0.21189619 0.14654175 0.16081605]\n",
      "[0.210825   0.15723145 0.15023005]\n",
      "[0.23550803 0.18206391 0.17550469]\n",
      "[0.205425   0.13882777 0.15663133]\n",
      "[0.22987866 0.1639012  0.1794969 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francois\\Anaconda3\\envs\\gti770\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "a1, f1 = GenerateModelDataFromVector(x1, y1, CreateDecisionTreeModel(9))\n",
    "a2, f2 = GenerateModelDataFromVector(x2, y2, CreateDecisionTreeModel(9))\n",
    "a3, f3 = GenerateModelDataFromVector(x3, y3, CreateDecisionTreeModel(9))\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n",
    "print(a2)\n",
    "print(f2)\n",
    "print(a3)\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_val, X1_test = SplitVectorData_Holdout(x1, 0.8)\n",
    "Y1_train, Y1_val, Y1_test = SplitVectorData_Holdout(y1, 0.8)\n",
    "\n",
    "Y1_pred = SVM_linear(X1_train, Y1_train, X1_val)\n",
    "\n",
    "a1, f1 = GenerateScores([Y1_val, Y1_pred])\n",
    "\n",
    "print(a1)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galaxies_norm = NormalizeData(Galaxies)\n",
    "#acc_neurone_holdout, f1_neurone_holdout = Neurone_Holdout(Galaxies)\n",
    "\n",
    "#acc_neurone_holdout\n",
    "\n",
    "#acc_svm, f1_svm = SVM(Galaxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
